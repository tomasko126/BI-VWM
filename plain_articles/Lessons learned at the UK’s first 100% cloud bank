
In May last year, with the ink still drying on the regulator’s guidance for cloud-hosted banking, OakNorth Bank became the first bank in the UK to bring its core systems live in the cloud.
The challenger bank had always wanted to run in the cloud, but at the time of its launch in March 2015 the regulator wasn’t ready to allow cloud hosting. So OakNorth started out with a system that ran as a SaaS solution, hosted in a private data center. Once the regulator gave the go-ahead, the bank migrated its systems to a virtual private cloud hosted on Amazon Web Services.
The decision to run in the cloud was made for business reasons, says the bank’s Chief Operating Officer Francesca Gandolfo:
We look at technology for the value it brings to the business, not for the gimmicks. We went to cloud because we believe it fundamentally helps our business model.
The bank reached break-even in August 2016 and tripled its loan book in the second half of 2016, profiting from a slowdown in lending by established banks in the wake of the unexpected Brexit vote in June 2016. Its smaller size allowed it to reassess the risk environment quickly and continue lending while others retrenched, says Gandolfo.
OakNorth specializes in lending to entrepreneurs for business ventures and property schemes. It has taken £250 million ($310m) in retail deposits from 7,000 savers and its loan book is in excess of £300 million ($372m), says Gandolfo.
Why go cloud?
She reels off a list of reasons for adopting the cloud, from flexibility, scale and creativity to security, cost, and being able to focus on the core business of banking.
Being an infrastructure host is not our core business. Why did we break even? Because of laser-like focus on things that drive the business.
Cost stands out as a key element, although not merely in terms of saving money. “We have a cost which is fit for purpose,” she says. The bank is free to upgrade or downgrade to suit the business, she explains, able to spend more when needed, while saving money on other elements that don’t have to be state-of-the-art.
For example, when introducing new capabilities, it’s better to over-provide resources so that there’s enough headroom for unexpected demands, she explains:
Don’t try to optimize from day one. If you stay too much skin-to-the-bone, things will fall over and fail. Do the right trade-offs.
Looking back, replatforming to AWS was a valuable learning experience, she says:
There are a few things we would have done different, but I would not go back and redo it because we learned a whole lot.
There is a huge amount of value in experimentation. Give people the freedom to try things and fail. There is some value in failure — but controlled failure, not reckless failure!
And she doesn’t rule out the possibility of replatforming again should the need arise:
We rebuilt the bank twice within a year. I think we have this down to an art.
We want to make sure we are robust and have our destiny in our hands.
My take
An interesting insight into the factors that come into play when migrating traditionally on-premise functions to the cloud.
Image credit - Sourced from OakNorth BankDisclosure - Francesca Gandolfo was speaking at Cloud Expo Europe Read more on: Cloud platforms - infrastructure and architectureFinancial services and fintechUse cases 