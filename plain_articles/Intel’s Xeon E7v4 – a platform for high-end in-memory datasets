
Software may be eating the world, but it does so with a set of silicon utensils. While Moore’s Law might be moribund, it’s not dead yet and continues to feed the voracious appetite of new software and cloud services for capacity and performance.
With the recently announced fourth-generation Xeon E7 processor, Intel provided fresh evidence that annual improvements in server chip technology are still the norm, albeit not as spectacular as in years past. Unlike the E5 series refreshed in March and designed for massively distributed cloud builders, the E7 is Intel’s mainframe chip, targeting monolithic, scale up systems and workloads that are the backbone of most enterprise IT organizations. These include databases, business intelligence and analytics systems, transaction processing, ERP, industry-specific technical applications and anything else using enormous data sets.
Given the hype around data-driven analytics, it’s unsurprising that Intel made it the software centerpiece of its rationalization for this year’s E7 iteration. Indeed, with only about 30% faster performance across a range of benchmarks than last year’s E7v3 product, it’s no wonder that Intel chose to emphasize improvements running actual applications over synthetic test results.
This is a wise move since real world scenarios play to other strengths in the chip’s design than improvements to raw horsepower. Notable is support for twice the number of CPU sockets per system and memory capacity, along with a host of microarchitecture and instruction set optimizations designed to improve transaction processing, virtualization and crypto performance along with overall memory bandwidth.

Speed through software optimizations, not just raw horsepower
Citing actual application performance provides Intel a better case for upgrades, however as we’ll see, the nascent market for large-memory cloud services for in-memory databases will likely provide a more significant long-term market opportunity. One example of the performance kick is a system for high frequency trading tick analysis from Kx Systems that runs almost three times as fast on a four-socket E7v4 versus the two generation’s old E7v2. It’s achieved by exploiting the new device’s greater number of cores, more advanced vector optimized instructions (AVX2) and faster DDR4 memory.
Similarly, a supply chain management suite from Brunel University in London achieves a 3.66x improvement in throughput time versus running on a previous generation E7v3 system.
These examples illustrate why IT should care about a seemingly incremental hardware release: it allows software to process larger in-memory data sets and do it much faster, creating opportunities for better, more timely business insights leading to more accurate and faster decisions. As we discussed last month:
By itself, a vast ocean of data is nothing but expensive noise, both costly to acquire and maintain. It remains noise unless filtered down into concise, understandable nuggets of information that can trigger business epiphanies and insights. These are the ‘ah ha’ moments that spark changes like business process optimization, new product and service creation and investment prioritization — the insights that turn big data into big profits.
Supersized, in-memory cloud services
The E7 platform, which includes the chipset, memory buffers and RAM, is an engine for software that can perform such data analytics alchemy. Given the shots Intel takes at IBM in its announcement slides, the main competition is the company’s POWER8 CPU (which we discuss here as part of budding open source hardware-software ecosystem). However, the battle is likely to be fought as much over the business of cloud providers as enterprise IT organizations.
As enterprises continue moving workloads to cloud providers, both IaaS and SaaS, there will be increased demand for the type of services that can handle massive in-memory databases and analytics and these will need big iron, scale-up hardware like the E7. While Intel’s scale-out E5 processor line is the current workhorse for cloud infrastructure, it’s not optimal for systems like SAP HANA, Oracle or SQL Server that can use terabytes of system memory.
As cloud builders add services for large-scale in-memory computing, they’ll need the hardware to match and given interest in the POWER architecture by Google, Rackspace and several Chinese cloud and telecom services, that buildout will provide new markets for both POWER and the E7 product lines.
The two largest cloud vendors, AWS and Azure recently unveiled compute instances designed for HANA. At Sapphire Now, Microsoft announced support for a range of SAP applications including:

Azure with multi-node support for deployments capable of scaling up to 32TBs of memory for SAP HANA Enterprise OLAP applications like SAP BW
SAP HANA on Azure with single-node support up to 3TB each of memory for SAP HANA Enterprise OLTP applications like S/4 HANA
New large memory instances based on the prior-generation E7v3 that scales up to four 18-core CPUs and 3 TB of RAM

Not to be outdone, the same week AWS announced the availability of a new X1 EC2 instance type using a slightly slower version of the same E7v3 chip (2.3 vs. 2.5 GHz) that Microsoft selected and very similar overall specs: four 18-core CPUs, 2 TB RAM and local SSD. Again, the target is HANA applications.
According to the announcement, the new instances “Meet the performance bar for SAP OLAP and OLTP workloads backed by SAP HANA,” and are suitable for migrating on-premise deployments of S/4HANA, SAP’s next-generation Business Suite, or earlier versions. Of course, horsepower like this doesn’t come cheap, with AWS 3-year Partial Upfront Reserved Instance Pricing starting at $3.970 per hour. While Azure didn’t release details, you can bet at will be at least as expensive.
My take
Conflating the news from Intel, Microsoft and Amazon illustrates both the need for prodigious in-memory database hardware and the likelihood that cloud services will become a favorite vehicle for its delivery. Given the capital cost of such terabyte-scale systems and software, which is measured in the millions, cloud services will democratize access to data analysis capabilities that were out of reach for all but the largest organizations. Indeed, IaaS availability of large-scale in-memory systems should unleash a spate of new data analytics use cases that will provide a competitive advantage to those organizations creative enough to apply previously unaffordable and unfeasible analytics techniques to their business data.
Likewise, just as they have done with more quotidian server hardware, cloud vendors will become an increasingly important and influential buyer of this type of mainframe-scale hardware and will begin shaping Intel’s E7 architecture, specs and product SKUs.
Image credit - Intel and Brunel UniversityRead more on: Analytics planning and data analysisInfrastructure 