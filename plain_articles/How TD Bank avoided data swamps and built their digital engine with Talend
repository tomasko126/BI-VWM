
The Talend Connect 18 keynotes pushed a heady new phase in next-gen applications, where portable/cleansed data (via Talend) and portable apps (via containers and orchestration a la Docker and Kubernetes) allows IT shops to avoid futile fundraising by moving from (expensive) legacy IT to cost-effective, modern infrastructures.
But this isn’t an IT-centric play. Following Talend’s vision, when you can achieve “any device, any cloud, anytime” portability, you now have the means to roll out next-gen apps, and pile up digital wins – within your streamlined budget.
Yes, those apps will likely become component-based microservices, mixed and matched using a consumption-based pricing model which incurs the cost of servers only when the demand occurs. Deep breath.
If this vision is even partially on track, it opens up possibilities even a snark-heavy tech skeptic like me can get behind, because it removes persistent tech and cost barriers. Of course, that still leaves the problem of culture change and business results – not to mention interpreting Talend’s well-cleansed/portable data in a useful way – but hey, I never promised you a rose garden.
I’ll have interviews with Talend leadership for you as we move ahead, as well as a notable talk with Docker CEO Steve Singh, who gets the line of business cloud via his time as Concur, as well as the limitations of the SaaS subscription model.
But there’s no better place to start than with customer realities. And Talend had some notable use cases to assess. This isn’t a startup/DevOps cult conversation anymore. Customer presenters included McDonald’s, Lenovo, AstraZeneca and TD Bank, the subject of this use case. Much to my relief, these weren’t modest pilot projects either.
Translating tech into business relevance
After his keynote panel appearance, I caught up with Joseph DosSantos, Vice President, TD Bank Group and Senior Vice President US Operations at TD. His self-described job role says it all:
My wife describes my job as a professional translator. I help technologists speak English.
And how the heck do you do that?
I think it’s mostly about the ‘why.’ The technologies that people deploy by themselves don’t provide any value. They have to be put within the specific context of delivering things to somebody that’s of value.
DosSantos advises technologists to integrate tech into processes. Deliver on the processes that matter most:
Every institution has certain things that it cares more about than others. Find a way to connect it to that thing. If you’re in manufacturing, you’re trying to take out costs. If you’re in banking, you’re trying to centralize around your customer experience. You’re trying to [address] cyber security.
An ambitious task – modernizing the data infrastructure
DosSantos’ team manages some crucial data transformation projects:
We are tasked with modernizing the data infrastructure for the entire bank at the enterprise level. Different lines of business are moving to adopt a centralized enterprise platform.
Past projects were typical of line of business tech: quick tech adoption soon turns into a new and unwanted kind of IT spaghetti.
We come from a federated environment where each of the different lines of business did their own thing. By doing their own thing, it created a bunch of security risks, because we had data all over the place, but it also created a lot of technology bloat – so many instances of the same kind of thing.
Several years ago, DosSantos and team rallied around a new mission: a modernized IT not unlike what I described in Talend’s vision. It’s about putting data in the hands of those who need it:
We set out to build something that we thought would scale up to meet the needs of other people for let’s say, 20th century and 21st century analytic needs. Meaning: management reporting and dash-boarding, but also predictive modeling, machine learning, artificial intelligence, and the like.
That puts DosSantos at the data core of digital transformation projects:
Describing it as the core is exactly right because at the end of the day, if you have the data and you have the analytics, and they can be made available in the context of those applications, then you’re in good shape. I don’t own the application stack, but we own the smarts – both the data and the capability to make people create insights.
DosSantos says they started this centralized program with “building blocks” such as:

A data lake
A common ingestion framework
Metadata tools

Those building blocks were the basis of a new foundation. Next: find a new way to work with the business. Early projects included:

A “wall-to-wall reporting environment” for TD Bank’s insurance business.
A “wall-to-wall analytics experience” for the commercial lending business.

Avoiding data swamps
Too often, data lakes become unwieldy swamps. TD Bank has been able to avoid that by using Talend to cleanse and structure their lake:
We, right now, use Talend extensively for data transformations in lakes. They help us move the data from A to B, and to put it into shapes and sizes that our businesses want to consume.
So far, DosSantos gives this Talend project an A. So how will they get to A+? Their data lake might be too controlled. Sometimes it’s difficult for business users to pull the data back out:
That’s a different problem. We have put ourselves into a position where improvements in metadata management will fix that. A lot of our discussions with Talend have been around the metadata space.
Building an internal search structure as intuitive and effective as a consumer search engine is no small task. DosSantos and I talked about why context is everything. If you type in “Mike’s Pastry,” you don’t want a result from across the country. DosSantos thinks he can solve that problem with Talend and metadata:
I think about metadata as creating the context around the data, so you can provide the right answers and that’s what we’re focused on working on with Talend – to figure out a much more rich, holistic picture of that data ecosystem.
The data chaos of line-of-business-tech has been reigned in. But making that data accessible is high stakes stuff. Putting in the right data controls in is a big resource drain. That’s where machine learning and automation could come in:
We are looking to automate what are often really arduous controls. We, like everyone, are scared to death by what happened to Equifax. We don’t want our name to be a punch line. As a result, we’re highly protective of the data that our customers expect us to be protective of.
My take – on results and AI futures
TD North has more worthwhile data projects than I have time for here. But getting back to Talend’s premise I began this article with: that premise only works customers can speak to results. So what does DosSantos have to say about that?
The idea of having data available, centralized, is not new. What we were able to do is, I think, take advantage of a technology wave to integrate it in a way that was new – and cost effective.
And yes, those results can be quantified, and the savings aren’t small. They pay $100 per gig in their data warehouse, but only a 1.62 per gig in their Hadoop data lake.
Making data accessible has helped the business users get closer to their customers, and personalize offerings. TD Bank, based in Toronto, contends with different mortgage rules in Canada that raise the stakes on customer/mortgage retention. Analyzing customer data in fresh ways will prove key to personalizing future mortgage offerings.
In January, TD Bank acquired Layer 6, an AI company, which bolstered DosSantos’ team’s efforts to deploy AI and big data capabilities. Fraud protection is one scenario they are looking at closely. There is more translation work ahead, but with a twist. The business is new to AI, and addressing their questions and/or fears will be important for the AI initiatives ahead.
Image credit - Magnify Glass Loupe on the Volcanic Rock © underworld - Fotolia.comDisclosure - Talend paid for the bulk of my travel expenses to attend Talend Connect 2018. "I never promised you a rose garden" is lifted from the 1964 novel title.Read more on: Analytics planning and data analysisCRM and customer experienceDevOps NoSQL and the open source stack 