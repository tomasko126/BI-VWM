
Most social media and messaging platforms have some kind of moderation and selection policy. This week Twitter’s version is under fire for its failure to stem online harassment.
As BuzzFeed’s report makes clear, the sporadic inconsistency of Twitter’s “ad-hocracy” makes its operations unusually opaque, even to those inside the company. But lack of transparency is a hallmark of moderation throughout the Internet, as a longform report earlier this year in the Verge made abundantly clear:
While public debates rage about government censorship and free speech on college campuses, customer content management constitutes the quiet transnational transfer of free-speech decisions to the private, corporately managed corners of the internet where people weigh competing values in hidden and proprietary ways.
… moderation practices with global ramifications have been marginalized within major firms, undercapitalized, or even ignored. To an alarming degree, the early seat-of-the-pants approach to moderation policy persists today, hidden by an industry that largely refuses to participate in substantive public conversations or respond in detail to media inquiries.
It’s not only comment and message moderation policies or trending topics selection that operate according to ad-hoc rules defined on-the-fly by hastily recruited, often overworked and under-regarded teams at social media sites. The need to write interfaces for a new generation of artificial intelligence agents is bringing unconscious bias into the world of enterprise applications. The next hot job in Silicon Valley is for poets, wrote the Washington Post in April:
Behind Apple’s Siri, Amazon’s Alexa and Microsoft’s Cortana are not just software engineers. Increasingly, there are poets, comedians, fiction writers, and other artistic types charged with engineering the personalities for a fast-growing crop of artificial intelligence tools.
But as the New York Times more recently revealed, some are worried that these bots are being realized in ways that discriminate against those who don’t conform to the mainstream white guy culture of AI development teams:
Predictive programs are only as good as the data they are trained on, and that data has a complex history.
Histories of discrimination can live on in digital platforms, and if they go unquestioned, they become part of the logic of everyday algorithmic systems.
… algorithmic flaws aren’t easily discoverable: How would a woman know to apply for a job she never saw advertised? How might a black community learn that it were being overpoliced by software?
We need to be vigilant about how we design and train these machine-learning systems, or we will see ingrained forms of bias built into the artificial intelligence of the future.
Even the way conventional applications are designed can steer us in ways we’re not aware of, as former Google “design ethicist” wrote in a May essay on Medium. The entire essay is an eye-opening review of the myriad ways in which application designers beguile us, beginning with the selection of items in a menu:
The more choices technology gives us in nearly every domain of our lives (information, events, places to go, friends, dating, jobs)  —  the more we assume that our phone is always the most empowering and useful menu to pick from. Is it?
The ‘most empowering’ menu is different than the menu that has the most choices. But when we blindly surrender to the menus we’re given, it’s easy to lose track of the difference.
My take
While we’re wise to the biases of traditional media, we’re more naive about the many subtle new ways in which digital tools can surreptitiously influence our behavior or filter the information put before us. Even publishers and application providers are often ignorant of the power they unconsciously wield over us. Consequently they fail to set proper policies or invest adequately in the resources needed to guard against abuse of that power. Society and business both need to become more alert to these issues and engage in serious debate about them.
Image credit - Blue eye superimposed on circuit board © mickyso – Fotolia.comRead more on: Content marketingCRM and customer experienceDiversityMachine intelligence and AISocialUX and application design 