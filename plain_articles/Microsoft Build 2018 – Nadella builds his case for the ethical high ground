
An ethical Nadella
It was a philosophical Satya Nadella who kicked off Microsoft’s Build developer conference in Seattle yesterday, with the CEO choosing to drill down on the ethical and privacy issues that have dominated the media headlines this year.
In truth, it was an empathic touch and one clearly intended to have Microsoft position itself on the high ground while others still struggle to provide straight answers to some pretty simple questions (yes, Zuck, that’s you we’re talking about!). So Nadella pitched:
The world is becoming a computer. Computing is getting embedded in every person, place and thing. Every walk of life in our homes, in our cars, at our work, in our stadiums, in our entertainment centers, every industry, from precision agriculture to precision medicine, from autonomous cars to autonomous drones, from personalized retail to personalized banking, are all being transformed.
That’s the opportunity that we have. It’s in some sense endless. But we also have a responsibility. We have the responsibility to ensure that these technologies are empowering everyone. These technologies are creating equitable growth by ensuring that every industry is able to grow and create employment. But we also have a responsibility as a tech industry to build trust in technology.
The Industrial Revolution analogy for societally disruptive innovation, hardly original, was trotted out, but with the intention of making one point:
The core technologies of the Industrial Revolution, whether it’s the internal combustion engine or electricity, are nowhere to be seen, they’re invisible. I’m reminded of this Mark Weiser [Chief Scientist at Xerox PARC and regarded as ‘the father of ubiquitous computing] quote: ‘The most profound technologies are those that disappear, they weave themselves into the fabric of everyday life until they are indistinguishable from it.’
And that’s what’s happening, that’s the opportunity that we see. In fact, Hans Jonas was a philosopher who worked in the ’50s, ’60s, and he wrote a paper on Technology and Responsibility. He was not referencing as much the digital tech. And a lot of his work got picked up later in bio-techs and other fields. But he talks about, ‘Act so that the effects of your action are compatible with the permanence of genuine life.’
That’s something that we need to reflect on, because he was talking about the power of technology being such that it far outstrips our ability to completely control it, especially its impact even on future generations. We need to develop a set of principles that guide the choices we make, because the choices we make is what’s going to define the future.
Prove it!
Enough with the big picture stuff. What’s Microsoft able to point to in order to stake its claim to the high ground? Nadella started by citing privacy policy:
Privacy is a human right. We at Microsoft have enshrined a set of principles that ensure that we preserve this human right, protect this human right. We ensure that when we use data, it is to benefit the user. We ensure that the user is always in control of their data and its use.
GDPR [General Data Protection Regulation] is a sound, good regulation. We have been working hard to ensure compliance with it by end of this month when it becomes in effect. We have hundreds of engineers across the company building the compliance infrastructure. In fact, we’re going to help our customers who use our products and services get compliant.
But we know that this is just the starting point. It’s just like security – we’re never going to be done. We are going to continuously commit ourselves to work to preserve privacy.
Microsoft has, of course, been in conflict with the U.S. Department of Justice over the vexed question of whether it has the right to access data held on servers outside of the domestic U.S., in this particular instance emails on a server in Dublin, Ireland.
It’s a battle that’s rumbled on for years and one that has enormous implications for the global cloud services industry. The latest development was the signing into law by President Trump of the CLOUD Act, which the DoJ argues has removed any need for U.S. courts to get involved.
Nadella didn’t comment on that assertion, but did state:
No company has done more in terms of working hard to ensure that there is a framework of law that governs how legitimate governments and legitimate needs of governments to protect their citizens are balanced with privacy. We have had four cases against the U.S. government that we’ve litigated since 2013. One of them went all the way to the Supreme Court.
As for the CLOUD Act, he would only say:
We think the CLOUD Act is a good start. It creates a framework. We hope the rest of the world and the United States can create, in fact, an intergovernmental framework around this. Meanwhile, we will continue to do what we have done, which is to ensure that customers are in control and privacy is preserved.
Alluding to allegations of foreign interference in the 2016 U.S. election, Nadella picked up on cyber-security as his next proof point:
We need to act with collective responsibility across the tech sector to help keep the world safe. We recently formed a program to protect our democracy where we’re going to work with the campaigns, the civic society, other constituents, so that we can secure our political process, our democratic process. We also led a consortium of 34 tech companies with the Tech Accord to ensure that citizens across the world are protected from cyber-attacks. It’s the Digital Geneva Convention of our time.
And of course, he had to touch on the ‘killer robots are coming’ meme and address ethics in AI and machine-learning:
We need to ask ourselves not only what computers can do, but what computers should do. That time has come. We formed an ethics board inside the company, which is a very diverse group of people who govern the products we build, the projects we engage in.
We also need privacy-preserving AI or private AI. In many cases, you need to be able to take data, have it cross even organizational boundaries, and to be able to do that by using techniques like homomorphic encryption so that you can learn, train on encrypted data. We’re already working on some of these technologies. We have libraries that work with things like Azure ML. And we’re working with the healthcare and pharma industries. These are investments we are making today to ensure that we can all collectively make ethical AI choices.
Closing off before opening the doors to coding and development as the proper topics of the day, Nadella told delegates:
This is what grounds us, this opportunity and responsibility is what grounds us in our mission to empower every person and every organization on the planet to achieve more. We are focused on building technology so that we can empower others to build more technology. We have aligned our mission, the products we build, our business model, so that your success is what leads to our success. There’s got to be complete alignment.
My take
Janine Milne recently covered the rise of the Citizen CEO, those leaders whose ethical universe extends beyond the ‘day job’ of selling tech and keeping shareholders happy. It’s a breed of business person that we see more and more often in the tech industry and a generational development that’s all to the good.
Nadella spoke with considerable clarity on topics that wouldn’t necessarily have topped the discussion at a developer event a few years back. There will, of course, be those who will offer up plenty of examples of ‘why Microsoft has no right to the high ground’ – and many of them may well stand up to considerable scrutiny. But after the obfuscation from Facebook in recent weeks, I’m ready to give Nadella the benefit of the doubt here.
Image credit - Microsoft Read more on: Data privacyFuture of workGoverning identity privacy and securityIoT robotics and AIMachine intelligence and AI 