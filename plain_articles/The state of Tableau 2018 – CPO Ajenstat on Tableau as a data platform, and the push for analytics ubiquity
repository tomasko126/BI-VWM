
After the flurry of planes and Ubers and interminable Starbucks lines that constitute enterprise event season, it’s easy to become jaded.
Moreso when vendors miss huge opportunities to let customers tell their story, something I’ve vented with (hopefully) constructive spleen in my enterprise event survival series.
But not in New Orleans. Five minutes into his keynote, Tableau CEO Adam Selipsky left the Tableau Conference stage entirely:

Five minutes into opening keynote at #TC18, and Tableau’s CEO has already turned over the stage to customer Pfizer, sharing why Tableau is integral to their data-driven strategy. That’s how it’s done. So many vendors miss this chance in their eagerness to explain their strategy pic.twitter.com/GBzNI6n5qj
— Jon Reed (@jonerp) October 23, 2018
After two vigorous days amongst 17,000+ passionate data geeks, I got the state of Tableau from CPO Francois Ajenstat. Last year, Ajenstat told me about the impact of AI and why data analysts need to change. Yet I felt Tableau needed to change in some ways also – especially with enterprise-grade performance in mind. So where are we now? Well, we can start with the massive attendance of 17,000+ data enthusiasts. Ajenstat:
It’s exciting, because you get to see the impact that they’re having all over the world. Adam talked about the concept of analytics ubiquity, and what does it mean when you can truly make analytics accessible to everyone, and with the impact it could have. That’s a big theme that we want to ensure everybody is thinking about, not just keeping analytics to few, but to really open it up to everyone.
The push for “analytics ubiquity” is the perfect opening for Ajenstat to explain three big product announcements from the show:
The first one is the new Ask Data functionality. So, using natural language to talk to your data will make analytics accessible, because now it’s really just interacting in plain language rather than having to be an expert in drag-and-drop or analytics.
The improvements we’re making around data prep, to simplify data prep as people combine the data, but also with Tableau Prep Conductor, to schedule and monitor and keep data fresh, it’s critical.
But the last piece is that, in order for analytics to be used by more people, we have to remove the complexity of the infrastructure. And that’s where the new data-modeling capabilities come in, because it makes the data fabric transparent to the users.
Ubiquitous analytics is a worthy mission – but Prep Conductor is an additional license cost. How does Tableau decide which products be available to all customers? Ajenstat:
It’s a delicate balance because we don’t want to be the company that nickels and dimes their customers. We really think about the use cases. So take, for instance, Ask Data. Users can get to the same task in different ways, either through drag-and-drop, or through natural language. So it’s really two sides of the same coin. So you wouldn’t charge for something like that.
Ajenstat says all licensing decisions must meet this criteria: keep the SKUs simple: “We have three SKUs. We have Tableau Creator, Tableau Explorer, and Tableau Viewer – that’s it.”
But put the big announcements aside – I thought there were some sneaky big stories from the show as well. The ones that caught my eye? Those that pointed towards Tableau as an online data platform. A browse through the event tweetstream shows customers using Tableau in conjunction with Google Cloud, Snowflake data warehousing in the cloud, and so on. Announcements like the expanded partnership with AWS for a new healthcare Quick Start and upcoming SageMaker extension added to the reams of Tableau cloud news.
Tableau isn’t pushing their customers to cloud analytics, but that’s clearly where the data gravity is headed. But as Ajenstat says, this isn’t just a lift-and-shift:
As customers move to the cloud, they’re rethinking their entire data and analytics infrastructure. They’re going from traditional BI and saying, “Okay, if we’re gonna modernize our database, what are the best tools and solutions to use on our databases?” And it’s a natural synergy between moving to the cloud and replacing your analytics infrastructure.
That means Tableau has to step also. These changes might lead to better use of data, but they aren’t easy to make:
Change is hard because it requires users to do something different; it requires IT to do something different. So if you’re gonna go there anyway, take the leap.
Last year, Tableau expanded its extensions capabilities. This year, I saw the results all over the conference – enough for a separate article. One standout example? Automated Insights, which built a text-based machine learning engine that generates instant text context explaining each Tableau visualization.
Tableau has no shortage of analytics competition. But if it can turn traction with data analysts into becoming the Force.com of the analytics world – that’s a defensible position. That’s community morphing into products customers care about. The numbers back it up, with 25,000 downloads of Tableau Extensions, just in the three months after they were announced. Ajenstat:
When we talk to customers, they chose Tableau because of the ease of use of Tableau, but they also choose Tableau because of the skills, the ability to find people who can use the software. That skills development is so critical. That means partners, that means talented resources, that means a community that can support customers, too.
Last year Tableau painted the big picture on how AI will impact data analysts. So what’s the progress since then?
The overall message is still the same. We believe that AI and ML will not replace the analyst but rather augment the analyst. It is an ingredient technology that you’ll see everywhere. So we showed in the keynote that integration with Tableau Prep, where we have smart recommendations, smart cleaning of the data.
You’re actually seeing it in Ask Data, as natural language is part of the AI category, but there are smart recommendations in there… The more that people use it, the more that Tableau gets smarter on behalf of our customers.
So in Tableau’s view, data analysts’ jobs aren’t threatened by AI. But data analysts still have to change. For analytics ubiquity to become reality, data geeks have to empower others, not just slice and dice, right?
Definitely, but I do think that there’s two sides to that. On the one side, AI, ML, and those kinds of capabilities really gives customers back time that they can either use to do other things, or to do deeper and better analysis. On the other side, analysis is only as good as the people that you can share it with, and the actions that you take.
A big, big, big trend that we’re seeing is all about storytelling. How do I communicate my insights to drive impact? And that’s where the analysts can’t just be quants; they can’t just be crunching the numbers – they need to be communicating what the numbers say.
The wrap – for now
I showed Ajenstat a visualization I knew he would like, even though it’s not from Tableau. It’s a graph of how Tableau has outperformed the Internet software market since 2017. That matters, because in year’s past, Tableau’s volatility has been a distraction (their CFO credits strong subscription plan adoption and large deals driven by a new pricing model).
Last year, performance at scale was a big topic, and a driver behind the 2017 Hyper announcement. Ajenstat says that performance issues are something you never stop tackling, but he feels good about the progress:
We released Hyper in version 10.5 last January, and we’ve been improving it throughout the year. Tomorrow, you’re going to see another big improvement to Hyper, something we’re calling multi-table storage. Essentially that makes Hyper even faster to create and to query… Over 80 percent of our customers are using Hyper today.
Putting large-scale customers on stage like Pfizer early and often addresses questions of scale more than any announcement ever could. The analytics space has tons of competition, something Ajenstat and I discussed last year. But: not all will prosper. Tableau has momentum, but no prizes are being awarded in this marathon yet. I’ll share more of what I learned at Tableau Conference in upcoming customer use cases and show notes.
Updated, 2pm PT 10/31/2018, with several small tweaks for reading clarity – plus additional resource links.
Image credit - Photo of Tableau CPO Francois Ajenstat keynoting at Tableau Conference 2018 provided by Tableau.Disclosure - Tableau paid the bulk of my expenses to attend Tableau Conference 2018.Read more on: Analytics planning and data analysisCloud platforms - infrastructure and architectureCRM and customer experience 