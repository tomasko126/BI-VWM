
This will be something of a meandering post so bear with me as I attempt to thread between concepts that are not yet fully formed.
A New York court case involving Exxon Mobil tickled my debating neurons this week. Over at Inside Climate News, I saw this story:
ExxonMobil defended itself in court documents Friday following claims by New York Attorney General Eric Schneiderman that the company used two sets of books in evaluating climate risk, one set of numbers for describing the risks to investors and the other for business decisions. Schneiderman had described the practice as a “sham” perpetrated by the oil giant while Rex Tillerson was its chief executive.
If proven then this is serious stuff but then it won’t be the first – or last – time that we’ve witnessed numbers used to support specific arguments rather than representing a genuine realité. Ergo the response by Exxon Mobil lawyers:
“ExxonMobil’s use of different metrics, in different circumstances, to accomplish different goals evinces prudent financial stewardship, applying appropriate assumptions in appropriate cases,” the brief said. “There is nothing untoward or surprising about any of this.”
And if you want another ‘flip the switch’ example to dissect then check out how Uber changed its compensation plan.
Hum me a tune
Of course. In IT terms, that would be regarded as something akin to being unable to establish which is the master data, a common if tractable problem. In lay terms, the prosecutors are implying that Exxon Mobil is operating a series of terminological inexactitudes to suit its purposes under different circumstances.
Why should this be something of a rant? After all, we are used to accounting types making it up as they go along, providing nuanced information depending upon the circumstances and rarely raise an eyebrow when we see unexpected results.
The Exxon case is very much in the mold of ‘telling them what they want to know’ versus ‘telling us what we need to know,’ and therein we often find that poorly formed definitions make for difficulty in establishing which set of numbers are the most appropriate in any given circumstance. It’s a genuine problem that often calls into question why a given framework for reporting is needed in the first place.
But then in one sense it reminds me of an old Typhoo Tea advert from the days in the UK when monkeys were used as actors. Seriously, they were. In one scene, two monkeys are hefting a piano and one says to the other: “Dad, do you know the piano’s on my foot?” The other says: “You hum it son, I’ll play it.” Check this at about 3:40.
In extremis
Sometimes, the issue of frameworks gets taken to extreme lengths. The other week I read a bizarre report about the growth of financial anal-ysts covering the non-public, VC backed segment.
I carefully picked the words ‘bizarre’ and ‘anal-yst’ because of this:
Analysts say they rely on the occasional media report for scraps of financial information, in addition to talking to competitors, vendors and users. One analyst even worked as an Uber driver to prepare for a report on the company. Otherwise, they’re forced to make a lot of guesses.
“There is no information flow,” Mr. Rao acknowledges. But he sees that as an opportunity rather than a problem. “In the past, there’s been no real analysis out there,” he said. “When people invest in these companies, they don’t know what’s happening. There is total silence.”
The dearth of information results in wide variations in what analysts think companies are worth.
Heck – I can do that. But then it appears the emergence of this group comes down to this:
“A lot of people are getting pushed out or not getting the attention they want,” Mr. Rao said. “That was a big reason why I left also. I was following telecom services and equipment companies. It’s so tough to get noticed, you have three or four entrenched guys and everything goes to them. I add more value here, I’m in the media and talking to clients. I get more attention here. You feel like you’re adding more. A lot of people are feeling that you’ll see more people move around (into private stock research).”
So attention seeking is the rationale fueled by guesswork? Moving swiftly on…
Magical thinking
For me, the real problem comes in how this way of multi-variate thinking impacts the super hot AI agenda. As I’ve said many times before, those investing in machine based algorithms as the cornerstone for decision making need to exercise extreme caution. In his round up of Spring season events, Derek DuPreez noted on the AI topic:
…a lot of what we are hearing is still very much rhetoric. The real world examples being put forward are still few and far between, which makes it difficult to give you real insight into how use cases are being formed. That being said, it does appear that AI is being taken seriously amongst buyers, particularly as buyers consider how it could be used to streamline workflows and automate processes across the organisation.
In short, hype is far ahead of reality and yet we still see cases where consultants push AI related agendas that are rooted in the age old tradition of floating the efficiency balloon on the back of magical thinking around how organizations work and how efficiencies are achieved.
Context is king
At an everyday level, DuPreez reports that:
…some vendors are looking to AI to provide human-like recommendations to users. For example, quote-to-cash vendor Apttus is seeing how AI and machine learning can be implemented to give sales people effective recommendations. Elliott Yama, VP of best practices and knowledge management, said:
“It can actually give you a set of actions – I think you should sell this offering to this customer and I think you should sell it at this price, to be consistent with the actions that you’ve taken in the marketplace in the past.
So I can give that set of choices and even automatically bring that up as the starting position for that seller, if I have enough of that data and I can bring those analytics to bear. At this point we are beginning to bump into what we would call cognitive intelligence, the ability for the solution to understand, reason in a human like way and learn over time. So the system becomes more valuable in the insights that it provides as it goes forward.”

My initial reaction was a rather loud WTF? but then DuPreez is savvy enough to extract the context of what humans will do with these types of helper application. Check the full story, it’s worth the reading because among other things, Apttus is wise enough to realize that these are early days and we don’t yet fully understand whether the assumptions made for recommendations are correct in any given set of circumstances.
My personal view is that unless we fully understand what is being reported then the leap to machine based anything is at best dangerous. Think about it for a moment.
Play the music
The idea that a system can make a recommendation may work consistently well in the context of goods where it is relatively easy to make comparisons that fit a profile of needs. But what do you do about services?
Think back to the days when you were first in love. Other than the obvious physical attraction bit, what was your likely first thing of common interest? Music. And yet when you recall those days, while there may well have been swathes of common interest in musical genres I am willing to bet any money you like that there was also considerable cognitive dissonance on this topic.
Consider also the case study I recently wrote about a win for Host Analytics at LT Apparel. For me, the moneyshot is about the perceived quality of relationship in a situation where competing vendors were on near level functional terms. It is best embodied in this passage:
The MD was part of my discovery phase, he was available for calls, showed up for conference calls. I truly felt I was getting not just any partner, I knew who I was getting. I truly had a business partner who was guaranteeing success.
Bingo!
Emotional attachment
How do machine based methods of decision making account for this dimension?
As far as I am aware, there is no real world scenario under which machines acquire sentient capabilities that reflect that most human of characteristics – emotional attachment. It is what drives us to make irrational decisions upon which brands play, in order to keep us loyal, and which drives companies like Exxon Mobil (and the rest of us) to play with numbers for different purposes.
It may well be that as algorithms improve and as the mysterious world of machine learning becomes commoditized that the emotional challenges to perceived facts becomes part of our common technology experience. But in order to get there, we shall need a cadre of people trained in critical thinking that asks that most important of questions when in a decision making context: why?
Where are the thinkers?
Right now, I believe we are sorely lacking in the ‘thinking’ department. While the partial promise of machine based systems is to reduce our dependency upon gut based intellectual gymnastics, the kinds of challenge that are just over the horizon will require extremely sharp minds if we are to reap the full benefits of the artificial intelligence quotient.
Many of us will draw comfort from blithely if not subliminally lying to ourselves about what numbers and information are telling us. After all, we are far from alone in that regard as we seek to avoid the cognitive dissonance that critical thinking demands and which disturbs our otherwise finely honed worldview.
In the meantime, cue the consultants. They’ve not had many good outings since the financial crisis of 2008-10. And this kind of issue is right up their street…the equally misguided notion of comforting the disturbed through Pareto analysis and endless meetings now suffused with design thinking. What could possibly go wrong?
Image credit - © Patrick Daxenbichler - Fotolia.comRead more on: Analytics planning and data analysisMachine intelligence and AIRobotics 