
The explosive growth in public cloud services, which is responsible for the lone bright spot in IT infrastructure spending, makes it easy to forget that the vast majority of IT budgets still go towards on-premise systems.
IDC estimates that even in a year or two, over half of IT budgets will be targeted to on-site deployments. While IDC slices the spending pie into half a dozen categories, the shift is decidedly towards cloud infrastructure, both public and private. Of the 43% of IT budgets projected to be spent on cloud infrastructure, at 52:48 the ratio between public and private is almost even. Which raises the question of how organizations plan to build those private clouds?
The mega-clouds have spent billions of dollars creating custom software and hardware that allows them to efficiency carve up a warehouse full of servers delivering dozens of services to thousands of customers. Enterprise IT organizations are now discovering that going cloud is easier said than done.
IT execs and business users have gotten spoiled with the flexibility, scalability and cost efficiency of public services, so it’s unlikely that they will accept many compromises just to maintain ultimate control over infrastructure in their private fiefdoms.
Instead, they want what AWS, Google and Microsoft already have, but on their own terms and scale. Server VMs won’t cut it. Instead, enterprises want dedicated infrastructure that can be sliced, diced, expanded and contracted at will. One approach that’s gaining increasing attention, soon to become another IT buzzword, is composable infrastructure.
Composable basics and HPE’s push
While the term’s genesis stems from a caffeine-fueled marketing meeting, the concept merely refers to the ability to decompose physical hardware attributes into arbitrarily-sized resources that can be rapidly assembled into a logical pool.
Say an ERP application needs 64 cores, with 768 GB of RAM, 16 TB of flash cache and a half-petabyte logical volume. Meanwhile, a deep learning application requires 16 x86 cores with 512 GB RAM, plus 8 GPUs and 8 TB of flash memory. With a composable system, each application could be served from the same hardware rack with hardware resources that might be spread across 6 or 8 physical servers and linked via multiple high-speed network connections.
The first modern manifestation of enterprise composable hardware was arguably the Cisco UCS-M series, a blade system ahead of its time when it was introduced in late 2014, but canceled last year. While Cisco embraced the composable terminology, the concept has benefitted from the boost provided by HP Enterprise, which has made hardware composability the centerpiece of its Synergy project.
HPE intensified the composable messaging at its recent customer-partner-media dog-and-pony show, Discover, where company executives promoted reference customers, introduced new servers and a faster 25/50Gbps Ethernet fabric for connecting Synergy systems.
At the company’s Q2 2017 earnings call, CEO Meg Whitman said HPE has
…nearly 400 customers like DreamWorks, Redbox and HudsonAlpha, who have installed Synergy and we expect that to continue to ramp into the end of the year.
With such small numbers, some might construe Synergy to be an aspirational “hobby,” but as Apple proved with its TV box, hobbies have a way of turning into important catalysts for growth.
While HPE appears committed to a composable hardware strategy, it’s not alone, and as often happens, the most innovative technology comes from a startup.
Startup Liqid – a more open, high-performance approach
Liqid, no that’s not a typo, is a startup that emerged from stealth a couple years ago with a vague promise of disrupting the market with new technology to “fundamentally change the future of the data center.”
The vision became more clear last summer when the company announced a new all flash storage design using high-performance NVMe devices connected via a PCIe fabric. Unlike HPE, but true to its disruptive credo, Liqid takes an unconventional approach to stitching disparate systems into a composable cluster by using a custom-designed PCIe switch instead of Ethernet for the network fabric.
PCIe switches are nothing new, having been promoted by component suppliers like Avago (PLX) and Microsemi (Switchtec) as a means of creating high-performance storage networks. The same benefits of massive throughput, low latency and direct memory access to processors and system I/O makes PCIe attractive for connecting composable systems.
While the custom switch fabric forms the hardware foundation for Liqid’s platform, its management software is the brain that enables treating physical system resources like CPU cores, GPUs, memory, disk volumes and network interfaces as logical Legos that can be broken apart and reassembled as virtual systems.
Once recomposed, these systems are seen as virtual bare metal servers that can power any type of application. Indeed, composable systems can the selves be logically broken apart into VMs or nodes for a container cluster.
My take
Composable systems are appealing for enterprise data centers since they allow infrastructure to be precisely tailored to particular workloads.
The same composable cluster, whether encompassing a half dozen servers or several racks, could power a database requiring predictable performance using multiple dedicated CPUs, a GPU cluster used for deep learning, a VM server farm for traditional enterprise workloads and a Kubernetes cluster for microservices and cloud-native applications.
Such flexibility means that composable systems can achieve much higher levels of resource utilization yielding efficiency improvements with significant ROI.
The mega-clouds like AWS, Azure and Google have the scale and diversity of user needs that allow them to build hardware pods designed for specific types of services, whether data warehouses like Redshift or container clusters for serverless functions like Lambda.
Most enterprises lack similar scale, making it nearly impossible to efficiently build the types of dedicated infrastructure capable of handling both legacy workloads and next-generation private clouds without something like composable systems.
I remain skeptical that private clouds will ever be viable competitors to their public brethren. It seems more likely that organizations will build a hybrid composite that stitches together legacy applications and data sources with public cloud services, letting each infrastructure platform handle what it does best.
If private clouds are to become legitimate alternatives they will need some sort of dynamic, software-controlled hardware assembly.
Composable systems offer an intriguing solution to the requirements of modern infrastructure. It will be interesting to see how products from HPE, Liqid and its ODM partners like Inspur and others evolve and whether composable designs gain traction with enterprise IT organizations building next-generation data centers.
Image credit - Google data centerRead more on: Infrastructure 