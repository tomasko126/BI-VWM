
Alex Kipman
HoloLens 2 took center stage in Microsoft’s pitch to the Mobile World Congress yesterday, but away from Barcelona the technology is at the heart of the latest ethical divide between the company’s management and its employees.
Last November Microsoft picked up a two year, $480 million deal with the US Government to kit out the military with 10,000 virtual reality headsets built around a customized version of the firm’s HoloLens tech.
There’s no doubt about what the tech is intended to be used for. The tender documents for the Integrated Visual Augmentation System (IVAS) program makes clear that the goal is to allow soldiers to engage in 25 “bloodless battles before the first battle”. In other words, it’s a VR practice battlefield in which, according to the tender docs, “Soldier lethality will be vastly improved”.
It was a big win for Microsoft and a validation for practical applications of HoloLens, with the US Army becoming the biggest user to date. At the time, Microsoft said:
Augmented Reality technology will provide troops with more and better information to make decisions. This new work extends our longstanding, trusted relationship with the Department of Defense to this new area.
But Microsoft staffers aren’t as euphoric about this latest engagement as senior management has been. A group calling itself Microsoft Workers 4 Good published an open letter to CEO Satya Nadella and Chief Legal Counsel Brad Smith calling on them to pull out of the contract. The group says the new deal is a step too far:
We are alarmed that Microsoft is working to provide weapon technology to the US Military, helping one country’s government ‘increase lethality’ using tools we built. We did not sign up to develop weapons, and we demand a say in how our work is used…While the company has previously licensed tech to the US Military, it has never crossed the line into weapons development. The application of HoloLens within the IVAS system is designed to help people kill. It will be deployed on the battlefield, and works by turning warfare into a simulated ‘video game’, further distancing soldiers from the grim stakes of war and the reality of bloodshed. Intent to harm is not an acceptable use of our technology.
As well as canning the contract, the group demands that Microsoft ceases developing “any and all weapons technologies” and issues a public commitment to that effect. It also wants the company to appoint an “independent, external ethics review board with the power to enforce and publicly validate compliance with its acceptable use policy”.
Smith had previously suggested that Microsoft employees with ethical objections to working on certain projects would be allowed to move off them and onto other programs, but the Microsoft Workers 4 Good group rejects this as a solution:
Although a review process exists for ethics in AI, AETHER, it is opaque to Microsoft Workers and clearly not robust enough to prevent weapons development, Without such a policy, Microsoft fails to inform its engineers on the intent of the software they are building…There are many engineers who contributed to HoloLens before this contract even existed, believing it would be used to help architects and engineers build buildings and cars, to help teach people how to perform surgery or play the piano, to push the boundaries of gaming and to connect with the Mars Rover (RIP), These engineers have now lost their ability to make decisions about they work, instead finding themselves implicated as war profiteers.
Barca bound
Over in Barcelona, as HoloLens 2 was rolled out, the focus was very much on those sort of use case exemplars, with no mention of the tech’s biggest customer to date. Alex Kipman, Technical Fellow for AI and Mixed Reality in the Cloud and AI Group at Microsoft, pitched:
It all began with a simple question. How can technology adapt to people instead of people adapting to technology?… In 2016, HoloLens started the mixed reality revolution by bringing intelligence to the edge of computing. And over the last three years individual developers, large enterprises and brand-new startups have been dreaming up beautiful things, helpful things, inspired things. These mixed reality experiences have been used by hundreds of thousands of people changing the way we work, communicate, learn and play, which leads us to today, the next chapter in our journey.
Meanwhile CEO Nadella also nodded to the ethics question, without specifically mentioning the army deal, and focused on benign use cases:
I’m clear-eyed about the unintended consequences of these advances. That’s why we’ve committed to earning our customer’s trust and instilling trust in technology across everything that we do. That’s why we believe privacy is a fundamental human right. That’s why we prioritize cybersecurity, not just for the largest of companies, but for small businesses and consumers, who are often the most vulnerable to cyberattacks. And that’s why we build AI responsibly, taking a principled approach and asking the difficult questions like not what computers can do, but what computers should do. Our collective opportunity has never been greater.
Imagine a future where every construction worker can visualize what their project will look like in two days, or even in two weeks. Predicting what will happen with astonishing accuracy. They can understand the state of the construction site, no matter how complex. If they’re behind, to be able to ask why, what’s the problem and adjust, and get back on track.
In healthcare more than 1 million hospital patients fall each year just in the United States, 11,000 of them unfortunately are fatal falls. But, imagine a future where the precursors to a fall are being understood. And a nurse receives an alert before the patient falls. The nurse reaches out to the patient potentially saving a life.
And imagine a future where students in a classroom see historical objects in intricate detail, as their teacher describes them. They can walk around the artefacts, resize them, move them, creating their own learning museum and bringing the past back to life.
That was safer ground than some other comments he made later at the MWC when he told CNN:
We made a principled decision that we’re not going to withhold technology from institutions that we have elected in democracies to protect the freedoms we enjoy. We were very transparent about that decision and we’ll continue to have that dialog [with Microsoft staff].
My take
Another example of the rise of the Activist Employee in the tech sector. This is the second military-centric controversy that Microsoft’s been embroiled in in the last year, continuing to engage with the Pentagon’s $10 billion JEDI cloud contract after Google bailed, citing its own AI ethical principles as the reason. Google also pulled out the military’s Project Maven drone AI program, drawing an interesting line in the sand for other tech firms to cross.
Smith’s ‘you won’t have to work on this stuff’ line isn’t a solution; it’s just pushing the problem onto the sidelines. At the same time, those who disagree with the Microsoft Worker’s 4 Good stance echo the thoughts of Amazon’s Jeff Bezos that:
If big tech companies are going to turn their back on the Department of Defense, this country is in trouble.

 

 
Nadella’s comment about not withholding technology from democratically elected regimes is naive at best. Quite apart from the changing nature of regimes, there are plenty examples of democracies that have done terrible things to their own citizens, never mind other nation states. Still, as a holding statement, it’ll play to the wider gallery in Washington and to a large tranche of the electorate in the current political climate in the US.
But the ethics of all this are going to come back to haunt Microsoft – and all the other major tech firms – on a more and more frequent basis. Google’s publication of ethical principles are a good first step and there are of course other initiatives, such as Salesforce’s Office of Ethical and Humane Use of Technology, that point to the direction of travel. Microsoft needs to step up and stake its own claim to thought leadership that goes further than a CEO soundbite.
Image credit - Microsoft Disclosure - At time of writing, Salesforce is a premier partner of diginomica. Read more on: Cloud platforms - infrastructure and architectureIoT robotics and AIMachine intelligence and AISecurity 