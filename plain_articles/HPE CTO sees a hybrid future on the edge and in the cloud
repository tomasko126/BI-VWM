
If you’re not yet 100% clear on the future direction of Hewlett Packard Enterprise (HPE), which separated a year ago from the high-volume printers-and-PCs business of HP Inc, you’re not alone. Its reinvention as a standalone enterprise technology company is ongoing, with divestitures still in progress to spin out its 150,000-strong enterprise services business to CSC and its systems management software assets to Micro Focus.
Its leadership may claim to have set out a clear vision to become “the industry’s leading provider of hybrid IT” across on-premise data centers, multi-cloud and “the intelligent edge” of distributed networks and IoT. But how that will work in practise is still in the throes of being defined.
One thing that is clear is that HPE is doubling down on engineering, building on the intellectual and cultural assets of the old Hewlett-Packard Company and its legacy of prior and inherited acquisitions including Compaq, DEC, Tandem and 3Com. Recent acquisitions have reinforced this direction, including wireless networking leader Aruba, bought early last year for $3 billion, and this year’s acquisition of high-end computer maker Silicon Graphics International (SGI), which closed last month.
Setting the business context
At the EMEA rendition of HPE Discover in London last week, the company’s CTO Mark Potter spoke to industry bloggers, giving some insights into HPE’s technology strategy as the company forges its new identity in the world. With large areas of the show floor given over to technology exhibits including wireless networking, industrial robots and The Machine — a research project to develop a next-generation, in-memory computing architecture — Potter took pause to emphasize the importance of putting all this technology into the right business context.
A lot of times you have to not only innovate in the technology. You have to innovate in the business model as well on how you’re dealing with this. So setting up different go-to-markets, setting up different business relationships, thinking about how you get cost out of the supply chain, for example.
Often that means challenging the status quo and changing people’s mindsets — within HPE as much as elsewhere — before it’s possible to get their support, he adds.
A lot of times we forget, as an industry, how hard it is to change the people side of it. I spend a lot of my time on innovation, working the people angle.
I’m probably going to get in trouble for [saying] this, but 98% of my challenge is inside. We have the ideas. It’s how do I change inside? How to get people bought in, how do I find the money? How do I get people that are used to making profits and driving categories to understand that this area is disruptive and they need to take a risk?
Therefore the research and development teams are often pioneering future initiatives that haven’t yet been taken up more broadly within HPE.
I want to start small, because people a lot of times have trouble — especially when they’re heads-down focused — seeing a big inflection around the corner. You just have to start small and start moving in that direction and not over-think it.
So two directions that Potter spoke about are probably more significant in HPE’s future than many of its employees, partners and customers yet realize.
Redefining on-prem for the edge
The first is a redefinition of what on-premise means in the context of hybrid computing. While most of HPE’s customers think of on-premise assets as servers in traditional data centers, this new definition of on-prem introduces the notion of specialized workplace servers and data centers that serve the emerging needs of intelligent devices and the mobile networks they connect into. Potter explains that the data bandwidth and compute power required to service this ‘intelligent edge’ can’t be delivered remotely:
There’s this whole notion of a new on-prem that is emerging and we talk about it as a big trend. As we think about all the intelligence devices delivering analog data into the world — we keep talking about 20 billion [devices] — something is going to have to give.
All that data from a latency and a transaction perspective, and from a machine learning algorithm and response [perspective], is not going to go off into some gi-normous cloud, way away. So there’s going to be this notion of a whole new ‘on prem’ emerging in what we call IoT, [in] factory floors or automated devices.
That gives HPE an opportunity to put all of its software and hardware engineering expertise to work delivering converged systems that provide the performance, security and governance that enterprises are going to need in these environments. Potter and colleagues point to the example of Apple, which has succeeded with devices that combine software and hardware for innovative outcomes.
Workload-optimized computing
The second direction is a willingness to use more specialized components that are capable of executing the machine learning algorithms and other advanced functions that will need to run locally in collaboration with more distant cloud resources. Potter foresees a proliferation of more specialized servers deployed to meet these requirements, using new generations of chip technology such as FPGAs, and perhaps even exploiting new system architectures.
I think we are in a renaissance of what I’ll call workload-optimized computing. You see this now with Microsoft announcing they’ve put FPGAs in almost every single one of their [services]. You see Google talking about their machine learning …
When you’re running workloads at scale, you can no longer afford from a cost and a power perspective to throw the same exact tool at every workload.
We think there’s other technologies that will come along to further aid that. Part of The Machine project was creating a fabric that could allow processors to be brought to the data that were workload-specific. It may be an Intel processor, it be an Nvidia, it could be Google processor, it could be an FPGA with a custom Morgan Stanley app on it.
It won’t just be the processors that we see. It will be the technologies around them to enable this notion of a workload-optimized data center become more and more real over time.
My take
As someone who is paid to look three to five years into the future, CTO Mark Potter has to think several steps ahead of HPE’s rapid and ongoing evolution. Like all of the mainstream enterprise systems players — IBM and Dell/EMC being the other major players — HPE must undertake a huge transformation that is only partially complete, with no way of knowing what size or shape the market will be in once it reaches that destination.
The bet on a need for new on-prem architecture to bolster the processing and analytic power available to networks of connected devices is an astute one, although it’s hardly novel. The company is playing catch-up to earlier moves on this space by its rivals. Nevertheless, this is where the volume opportunity for HPE’s engineering skills is likely to be.
But as Potter makes clear in his remarks, the true challenge is not so much in product engineering as in adjusting business models and mindsets to a new market landscape. Maximum clarity about the end destination will help speed that adjustment, but as he also points out, what really matters is to establish proof points that show the new products and business models succeeding. We wait with interest to see that early evidence emerge.
Image credit - © Hewlett Packard EnterpriseDisclosure - I made my own way to Discover, HPE laid on dinner. Read more on: Cloud platforms - infrastructure and architectureInfrastructureInternet of ThingsMobile 