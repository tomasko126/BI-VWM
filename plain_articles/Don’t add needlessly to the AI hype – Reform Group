
Could use of AI (Artificial Intelligence) help make UK public services more efficient and potentially more effective?
Yes. Imagine services that could be personalised, responding to the individual’s needs instead of providing uniform services that only work for the average. Imagine public services that were proactive, solving people’s problems before they knew they had them, instead of only ever being what we have now – reactive. Or how about public servants empowered by smart support systems that would let them better detect, anticipate and resolve social issues with efficient, targeted interventions?
Sounds great. Should we mandate, then, its use across the sector in the same way we’ve directed civil servants to buy cloud-first, or for Whitehall developers to use Agile?
Sorry to disappoint you, but no – as to do so would mean not only clearing up some huge and so far unaddressed ethical issues, it would also mean an overhaul of a lot of the UK’s public sector data architecture.
This is the mixed, but convincing, judgment from Eleonora Harwich, a close observer of the growing use of AI and its techniques, such as Machine Learning, in the country’s central and local government. She said:
Not all AI is new, and no technique is a magic wand that can help you resolve all of your thorniest policy issues. Throwing any type of data into a convolutional neural net or a decision tree and hope for a perfect solution to a policy issue is truly wishful thinking, sorry.
Tough as that may be to hear in some over-excited quarters, it’s actually a wise piece of tactical advice from someone who’s spent the last two years closely monitoring the UK adoption of the tech.
Harwich is a Researcher at Reform, the non-partisan London-based think tank that frames itself as helping the public sector better deliver policy on the ground that can actually help achieve better social outcomes.
Currently working on a paper on the applications of AI in the NHS, Harwich has also published on the question of how AI could transform the way governments deliver public services. Her particular area of focus is not so much AI in general, as one useful application of the idea, so-say Machine Learning, where a computer can self-teach and reach potentially interesting new insights just by looking at huge amounts of data.
She’s drawn up her conclusions on the state of UK public sector AI success on the basis of close tracking of a number of its pioneering uses in social services, healthcare and law enforcement.
AI is an incredible medium that could help a lot, and there are definitely great examples right now of Machine Learning in action delivering results. But it just would not be either possible nor in my opinion appropriate to use these early successes as the basis for a pan-governmental push to AI in the same way we did for G-Cloud, no.
Data and ethics
Why so, if the software can help? Harwich points out that data is the fuel good AI needs to be useful, and the combination of poor quality information and its siloed nature in so many different parts of local, NHS and other public body data banks means it would be a very hard technical job to collate it at the scale such a project would need. Data would have to be cleansed of bias, even after we had done the groundwork in deciding which of this large mass of citizen records was even useful.
But that’s just half the problem – the other half, a moral and political one:
We just have not had a sufficient level of debate with the public on the issues of access, transparency and privacy that using data like this warrants. There’s also difficult ethical questions surrounding the use of algorithms in decision-making. Before we get the machines to make an ever-increasing number of decisions for us, we need to do a lot of thinking ourselves.
Harwich and the rest of Reform think that better communication about what AI really is and what it can do really needs to start happening. That’s a two-axis discussion; one is inside the public sector, where informed practitioners need to educate their managers about what’s real and what’s hype – regression analysis is sometimes classified as Machine Learning, but is it just a rebranding of a standard statistical technique as newly “intelligent”?
The other, she says, is between all of us and the public. That’s because AI and technology isn’t standing still – it’s coming whether we want it to or not. But what we must not let happen, she argues, is for a mistake or accident to happen that greatly affects citizens. Applying AI to public services means applying algorithms to an area of high risk because it will have an impact on people’s lives:
We need to break these important ethical issues down and communicate them in ways that are clear and understandable. The public deserves to know what’s happening here, and how it could affect them, positively and negatively.
In fact, now is the time society needs to be having this conversation, as we still have time to draw up strategies that could help deliver AI as a really positive game-changer. And the longer we leave it, the bigger the risk of that ‘accident’ happens.”
Harwich will be talking in more depth on the issues raised in this interview at THINK AI for Public Sector 2017, a joint/venture between diginomica/government and Think Digital Partners, which is taking place in Westminster on Friday 20 September. 
Her presentation is entitled, ‘Sir Humphrey and the Robots’, and will cover topics including how the government could move from a ‘piecemeal’ application of AI to a ‘wholesale’ one.
Go here to secure your place to find out more; attendance is FREE for qualified public sector professionals.

Image credit - Images free for commercial use Read more on: Digital government and public servicesIoT robotics and AI

