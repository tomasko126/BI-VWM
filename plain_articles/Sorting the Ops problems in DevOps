
Abdelghani Faiz
A recent survey, sponsored by CA Technologies and conducted by UK researchers Freeform Dynamics, has suggested that many organizations are failing to address what they have called ‘the key requisites for revenue growth’.
As the survey’s title suggests, Assembling the DevOps Jigsaw, one of the key issues seen right now is DevOps and making it work effectively.
The study groups the attributes that need to take on board into three main areas, across all of which organizations are falling short:

a business-led approach.
skilled and collaborative IT resources.
the adoption of key controls.

That last factor, the adoption of key controls, may not be the sexiest issue to address, but it sure as hell is likely to be the one that manages to cause the most trouble, especially when the complexities of full-on DevOps environments become the mainstream option.
The survey quotes Benjamin Wootton, Co-Founder of DevOps consultancy firm, Contino, with this piece of salutary advice:
European organizations need to exercise caution, ensuring they adopt DevOps best practices. Taking a business-centric approach, making sure IT is properly skilled and working collaboratively, and putting the necessary enablers and controls in place will accelerate success in the application economy.
Ferreting out DevOP problems
In an environment where many small applications components may be deployed at what seem today to be alarming rates – some US online services vendors claim to hit rates of over 300 deployments a day – ensuring that they all have the intended outcome they were designed to provide can be a long-winded process.
Given the increasing amount of collaboration between these small applications and components of larger applications, any issue with just one of them can ripple out to create a serious problem with the performance of a particular business process.
If the only indication of a problem is that the KPI dashboard indicates that a sector of the business – for the sake of argument, Sales – is now diving into the red, then tracking down the cause becomes a major imperative. The report observes:
One in three users we’re in contact with have exactly this type of scenario, telling us that they have burned their hands in the past by improper deployment of new business logic which has then broken the system. The issue is that it has taken them time, maybe a week, to figure it out. It can also mean they have lost several days of the ability to trade at all.
That is the business bottom-line view of the problem from Abdelghani Faiz, one of the founders of Dusseldorf-based Integration Matters.
The company has pitched into the Business Activity Monitoring corner of the systems management sector, with tools that can be deployed to monitor specific applications and services, rather than the traditional approach requiring a complete, end-to-end deployment of a ‘total’ monitoring solution.
That technology, however already looks set to take the company into new market sectors, and in particular the near real-time monitoring of the impact of DevOps code deployments on business processes. Faiz explains:
Users can now build reports that show the ripple down effect of code deployment issues, for we now know exactly when the component has been updated and what are the performance changes after that. Most management tools won’t tell you this type of data. They will tell you how you got to the point of deployment, or what the release cycle was. But they cannot tell you anything about how the systems worked both before and after the deployment.
Known as nJAMS – which stands, in a self-deprecatingly truthful way, for `Not Just Another Monitoring System – the technology provides IT management and DevOps teams with a range of monitoring services that can set the performance of applications and applications components against a timeline. It then becomes possible to track the impact of any code problem, which normally shows itself via a change in the performance of the application or component.
This has a ‘backwards’ capability where nJAMS can find old, undocumented patches in legacy applications that were created by Ops Teams, often urgently, when applications stopped running for whatever reason. These got the applications working again at the time, but can subsequently cause real problems with later updates or API-linked collaborations with other applications, and be very difficult to find.
These are a good example of the ‘nobody knew’ problem, for the patches are often undocumented, and the operator that wrote them has often moved on. It is also a problem that could spawn very quickly in a DevOps environment unless the best of best practices are rigorously applied, not least because of the speed with which application components can be deployed in a production environment.
The need for speed
If there is a problem with a process, there is a need to identify it in as close to real time as possible, and identify the specific application or component that is the cause of the problem. The cause may lie in the code of any one of several hundred other application components and their interaction with the new component. Knowing what application components are part of an application or service, at any point in time, is crucial.
With multiple small developer teams having the capability to work on their own projects, and upload their ‘product’ as and when ready, there are many advantages in business agility for a business. But it can also have dangers if the administration gets even the slightest bit out of step.
It is essential that all the current components are known, but it is equally important that any problems they cause can be not just identified, but pin-pointed to a specific version of a specific application component, deployed at a specific time. The more granular this can be, and the faster it can be achieved, the better it is for the health of the business.
So what nJAMS does is mark the deployment of every piece of business logic on the time-line. This can then be compared with the other reports generated by nJAMS, such as response times or other performance indicators.
Whenever messages flow between applications, nJAMS captures the content and adds it to the database of events and timings so that a chain of events for each process can be built up. With this it becomes possible to identify what processes are failing and point to where the problem lies.
So as soon as an issue is detected in any of the operational and performance records, that point can be correlated with whatever deployment event immediately preceded it. In that way, the specific component that is implicated as the cause of a problem can, in near real-time, be identified and withdrawn and the evidence of the problem it is causing gathered up. It can then be modified accordingly, and re-deployed.
According to Faiz, this gets round the issue of most other monitoring systems taking time to detect that there is a performance issue to resolve. The danger with DevOps is that other applications and components, some of which may even interact with the suspect deployment, can be deployed before most systems are able to observe and indicate that there is a problem.
That is when the IT teams will have the job of unravelling several deployments at the same time in order to find the culprit.
The system also versions the applications that are running at any point in time. It is not uncommon for different versions of the same application to run different aspects of a process, and it can be important to know that this is happening, when it is happening and which versions are running what tasks with a process.
In order to build up a comprehensive picture of the processes, the nJAMS allows users to classify processes, for example as a new use case or as a variation of an existing use case. It is also possible to identify all the processes involved in what a user might consider a single process, for many of them are made up of many smaller sub-processes.
My take
DevOps certainly looks like being the ‘next big thing’,  but it does come with dangers, not least of which is businesses stalling because some minor error in a complex mesh of collaborating applications is preventing the normal flow of business through that mesh. Quick ways of finding the applications causing those errors will, therefore, be essential. nJAMS looks like it will be one of them.
Read more on: DevOps NoSQL and the open source stack 