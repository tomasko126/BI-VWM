
Governments and the public sector needs to take an active role in the development of artificial intelligence (AI) and the impact it could have on society. There are two elements to this. Firstly, what does the increased use of automation mean for the Civil Service and delivery of services to citizens? And secondly, what role should the government play in influencing the impact of AI on peoples’ lives?
The recent Think AI for Public Sector event in London saw a whole host of interesting discussions from a wide variety of speakers, on the growing prevalence of AI tools. Topics covered included case studies from local government, MPs talking on the importance of the fourth Industrial Revolution, and think tanks speaking about the potential impact of AI.
Off the back of the event, I thought it may be interesting to collate some of the broad themes that emerged. It is by no means a comprehensive list, and many of the themes will be familiar, but I thought it could be a useful/dynamic resource going forward to track discussions.
Jobs and skills
Inevitably, much of the discussion on the day focused on the impact on jobs and the workforce. Whilst some predictions have cited up to 50% of jobs being wiped out by AI in the not too distant future, some speakers at the event said that this could be too negative a take.
Yes, it’s hard to deny that plenty of jobs are ripe for automation, but chief executive of innovation foundation Nesta, Geoff Mulgan CBE, said at the event that plenty of new jobs will also be created as a result. Jobs that rely on human interaction and are often provided by the public sector – carers, teachers, etc.
However, whilst this may also be true, concerns were consequently raised about how and if the public sector will be able to fund these new jobs – given the appetite for reduced public spending in recent years and an unwillingness to raise taxes. Equally, are the right skills being taught in schools to compensate for the lack of jobs in other areas? It is predicted that core skills required will be focused on problem solving, creativity, team work – and criticism was thrown at the current UK school curriculum, which favours repetitive learning, exams and memory tests.
Equally, the government should be investing in retraining programmes for people mid-way through their current careers. The speed at which AI may have an impact on the workforce could mean that there isn’t enough time to wait for future generations to fill the jobs.
Blue and white collar workers also can’t be left behind in this, as some workers have been left behind during previous industrial revolutions. Whilst new jobs may be created, can we retrain people with the appropriate skills so we don’t have lost sectors of the workforce, unable to participate?
Public opinion and the need for institutions
Tied very closely to the discussion on jobs, is the perception that the general public feel very uneasy with the onslaught of AI and AI-enabled services. There are many facets to the unease – job loss, a lack of insight into how data is being used and a general uncertainty about dealing with machines for what were traditionally human interactions.
It’s undeniable that AI will proliferate regardless, but the government needs to be aware that engaging with the public, experts and innovators on the topic will be necessary to ensure that society moves along with the developments in AI at a pace that makes everyone feel comfortable.
One expert on the day cited the need for creating new government-backed institutions that could help with this. Institutions that collaborate with the technology community, regulators and the public to ensure that the AI activity that is taking place sits well with citizen expectations. The example of care.data was used, which was an NHS project to use patient data to improve services, but ultimately failed because the government didn’t have the foresight to manage public unease/expectations. Getting this right requires stakeholder engagement at all levels.
Accountability and transparency
One of the most interesting questions from an attendee on the day focused on the need for accountability and transparency frameworks, to ensure that AI-enabled services are implemented effectively. The delegate asked something along the lines of – “Driverless cars could well mean safer roads in the future. But if one driverless car crashes and kills a bunch of pedestrians, who is accountable? Equally, will society accept machine mistakes, if the outcome is still safer roads overall?”
The point is, humans generally are willing to accept a greater level of error from humans than they are machines. Machines could be right 99.99% of the time, but one big mistake feeds into the unease.
People will want insight into how data is being used, so they understand the decisions made by the machines. Equally, insight and transparency should make errors made more palatable. However, questions remain about who is accountable when things go wrong. Is it the company that owns the algorithm? Is it the developer? Is it the machine? A clear ethical framework needs to be introduced for how AI is introduced and operated, because, I believe, the public won’t just accept an AI-enabled service blindly – even if it’s convenient and works most of the time.
The problem of bias and diversity
AI algorithms are often racist and sexist, amongst other things. This is for a number of reasons. One, they are often fed historical data that is biased towards certain sections of society – but then applied using the assumption that it will suit all. Two, algorithms are created by people that inevitably have their own bias/prejudices.
There are plenty of examples of machines and services being biased towards people of colour, women, LGBTI people. This is also a problem for services that aren’t AI enabled, because people themselves are inevitably biased. However, if we want to get this right going forward, we need to think about how we can reduce/eliminate bias from autonomous services. If we don’t do this, we risk huge parts of society being excluded from the benefits of AI.
Equally, we heard during the event about how local government is experimenting with AI-enabled chat bots to interact with citizens. However, the councils in question were having to do a lot of work with the creators of the AI tool to ensure that it catered for a diverse society – not just White British people. We need AI that works for all, not just the few.
Government keeping up
The government’s ability to keep up with the quick changing nature of the AI revolution was at the forefront of peoples’ minds on the day of the event. Governments generally haven’t had the best track record on regulating the internet economy – everything from ensuring that services are used safely, to a more effective tax system to collect income from the internet giants.
This will become even more pertinent as AI develops. How is citizen data being used? What will it do to counter job losses? Is it investigating the prospect of introducing a Universal Basic Income? How will it ensure that technology companies act responsibility? What about an ethics framework? How will it hold people/companies to account? What will the impact be on the legal framework? Is it investing in the right skills?
These are many of the topics discussed in this piece, but the government can’t afford to sit on its laurels for this. If predictions are accurate, AI will accelerate rapidly and the impact will be felt far and wide. Government needs to be proactive in keeping ahead of the curve, engaging with stakeholders and anticipating what it could do to ensure that the AI revolution in the UK is a successful one – not one that works for the few.
Managing expectations
Given the hype and rhetoric circulating around AI, you’d be forgiven for thinking that machine learning and automation could fix all of government’s age-old problems. However, within the context of what is possible with AI, much of the technology is still relatively immature.
If you look at the problems discussed above, many of the outcomes that AI is aiming to achieve are still being figured out. And on the day of the event, the local government organisations that spoke about the implementations, warned that projects should start small and tread carefully.
They said that organisations should focus on achieving focused returns and then building on these to broaden the scope. AI should be used to delight citizens and also make the lives easier for back-end staff – but not at the expense of excluding certain sections of society, and with the expectation that plenty of work will have to be put in to get it right.
Image credit - Images free for commercial use Disclosure - diginomica works in partnership with Think Digital Partners, the creators of Think AI for Public Sector 2017. Read more on: Digital government and public servicesIoT robotics and AIMachine intelligence and AI

