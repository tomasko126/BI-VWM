
Flash. Aha. Etc Etc.
One of the annoying things that many tech vendors do now is jump up and down, thumping their chests and claiming how disruptive their latest technology is.
The irony is, not only does this have a strong potential to put customers off – the last thing they need is to have their businesses `disrupted’ by choosing a technology – it also usually masks a much more important positive.
This could be seen in action at an HP event this week covering the surge in growth for high capacity solid state Flash memory systems across the board. As Chris Johnson, EMEA Vice President and General Manager of the company’s Storage Division put it:
Flash-based storage systems are not just a storage issue. The increases in capacity, the reductions in cost, and the data management tools now available for them, are providing customers with a major business process re-engineering opportunity.
In fact he sees the impending demise of the traditional datacentre model as enterprise users start – now – on a major rip and replace approach to existing data storage systems. The current background in the marketplace of an at least temporary dip in storage systems sales of around 12% is, quite possibly a sign that this process has started, as Flash-based systems can deliver significantly greater storage capacity, in a much smaller byte-for-byte form factor, and at a much lower byte-for-byte cost. Flash storage sales, by comparison, have risen 500% in the last year.
Johnson sees this trend continuing – indeed accelerating as the management software is extracted from the systems to become stand-alone tools and the storage hardware becomes a classic semiconductor-based commodity product.
So while at present HP’s Flash offerings range up to single-SKU `boxes’ offering 15 Petabytes of storage with full management software integrated in, that software (which should in theory be the company’s future `secret sauce’ in helping users create new, re-engineered and re-architected business processes) will be available to work with any commodity storage, from Tier 1 Flash systems through to Teir `n’ near-line tape backup systems.
Moore’s Flash
The workings of Moore’s Law suggests the next iteration of Flash memory devices will lead to starting levels of several hundred T/bytes for a standard 2U rack system. HP itself already has a starter kit system with 7 T/bytes of usable capacity in such a box, and one of its smaller 3PAR systems already offers 280 T/bytes of storage in two 2U rack systems. Without management software embedded into such systems, many vendors will be competing for customer interest with huge capacities at increasingly knock-down prices.
The separation of management software from the boxes themselves should also add greater flexibility when it comes to customers building not just Software-Defined Storage systems but the `Software-Defined Everything’ that will be the foundation for widespread business process re-engineering and the `dissolution’ of the traditional datacenter.
The combination of Flash storage systems, hyperconverged compute resources and Software-Defined Everything environments will mean that system architectures will become driven purely by the logic underpinning new business processes, not the need for resources to be located in specific physical locations.
Flash. Uh huh. Etc Etc.
This also plays directly into the managed and cloud service providers, for whom the purchase of very large Flash data storage systems for high performance and expansive Teir 1 service provision will become standard practice – indeed, as Neil Thomas, Product Director of managed and cloud service provider, Claranet, says, it already is an active part of the development plan:
Storage is becoming a very hot topic with customers, because with newer applications the quality of experience is directly affected by the storage that is supporting it. Poorly performing applications can hit the bottom line of our customers.
At the same time he suggested that all Claranet’s customers are starting to become `software’ companies – in essence, businesses defined by the software they are using. This means high performance storage moves much more centre-stage, rather than being a useful afterthought.
The company has already started to put in flash storage arrays, with the existing disk storage moving to roles in Tier 2 backup.
In addition, it is also now able to offer users a range of different service management capabilities, such as de-duping, as tools or as included services. On top of that, it also has the fall-back position of being able to work with HP to offer customers the full range of HP management tools if that is required. Thomas says:
We already offer customers infrastructure management services, but I do see that trend developing to the point where the availability of these tools means we can offer them full data management services, freeing them up to concentrate even more on their own core businesses.
According to Johnson, this is where HP’s ultimate justification for the troubled acquisition of Autonomy will really come into its own. Its capabilities in data management, such as controlling the exponential duplication of unstructured datafiles as they get shared will, he suggested, prove to be a major advantage for the company.
There is one potential fly in the Flash storage ointment, however, and one that could cause some significant problems in future. That is the issue of data storage conversion and, longer term, format and protocols standardisation.
Flash is hardly likely to be the end of the line when it comes to storage technology developments and the problem of incompatible formats and protocols is a real one that the storage system industry is still not facing up to, as analyst Tony Lock from Freeform Dynamics observes:
One really important factor is the increasingly urgent need for a self-descriptive metadata standard. This just has to be developed so that all data can be transitioned to future data formats/storage formats in future, and remain readable. There is, however, no sign of this coming along any time soon, and will probably require users to start beating up the vendors so they feel obliged to get together to produce it.
The big underlying trend of Flash storage Lock sees is the change in customer expectations. For example, a recent survey conducted by Freeform Dynamics suggest that the majority of users feel that current infrastructures are now only future-proof for as little as three years.
But currently, users still expect a storage lifecycle of four to six years, and are looking for five year maintenance contracts at the moment. Lock notes:
A major hurdle is getting the ultimate budget holders – often the CEO and CFO rather than the CIO – to understand that storage is now a separate entity and no longer comes as an integral part of some other system, such as a server box. Getting the board to buy in on that concept is still very difficult.
The other hurdles that users see are the risks associated with change, data migration, risk of data corruption, and a perceived reliance on external, third party skills. Against that must be set the survey results showing that they are also seeking ease of management and richer management tools, with systems that are easy to install.
My take
Two separate issues emerge here. One is that use of the word `disruption’. Silicon Valley companies in particular now vie with each other to be the most ‘disruptive’ yet, as Lock points out, one of the big fears for customers is the risk associated with change. So thumping one’s chest and shouting `we’re gonna mess you up real good’ is hardly an encouraging marketing tactic.
The second issue is that this really is a possible inflection point on companies transforming their business processes, all of which will be based on the ability to store, access and exploit in real time the vast gobs of data that they will most certainly be generating.
Read more on: Infrastructure 