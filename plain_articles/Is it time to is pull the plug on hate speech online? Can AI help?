
The three deluded perpetrators behind America’s horrible week of killings and bombing attempts had one thing in common—they left behind, in plain sight, a long trail of vile, offensive and threatening social media posts that could—through AI or human monitoring—have triggered a warning or a human intervention. But, should they have?
First, there is the problem that freedom of expression is enshrined in the First Amendment to the U.S. Constitution. Does government or anybody else have the right to stop individuals from exercising their First Amendment right to freedom of expression although they have not yet committed a real-life crime? Secondly, do we have AI and machine learning software that is advanced enough and sensitive enough to sort out the dangerous loonies from the harmless nut cases without restraining their Constitutional rights?
The recent spate of hate crimes offer a few clues about the kind of people who are likely to be radicalized by online hate and interaction with other haters.
Minutes before he entered the Tree of Life synagogue in Pittsburgh and killed 11 worshippers, and wounding 6 others, Robert Bowers chilling tweeted:
I can’t sit by and watch as my people get slaughtered. Screw the optics. I’m going in.
Bowers biography, which could be found on a social media platform called Gab— a refuge for neo-Nazis and white supremacists who have been kicked off Twitter and Facebook, said that “Jews are the children of Satan.” His posts were filled with hate-fueled rants about Jews and the banner and the image on his page was a reference to a white supremacist meme.
Years before he killed two women at a yoga studio in Tallahassee, Florida, Scott Beierle was posting YouTube videos in which he called women “sluts” and “whores,” and ranting about women who canceled dates or gave him their phone numbers even though they had boyfriends, and talked about ripping their heads off.
Cesar Sayoc, the man arrested in connection with bombs mailed to CNN and several critics of President Donald Trump, threatened Democrats on Twitter and Facebook. One tweet sent to former Vice President Joe Biden by Sayoc included an image of Biden’s home with a target superimposed on it and read:
Hug your loved son, niece, wife family real close everytime U walk out your home
To make matters worse, potentially violent people tend to find each other online and reinforce each other’s prejudices and volatilities. There are hundreds of welcoming online spas where creeps of all persuasions can easily slip into a warm communal bath of like-minded mendacity. Which ones of them are going to “act out” is harder to predict.
But…First Amendment
Like so many things about online behavior, the moral, legal and practical implications of hate speech and how we should respond are vague and unresolved. While offensive and threatening and probably nasty enough to get you banned from Twitter or Facebook, do these dark thoughts and unhinged rantings present an imminent threat to other people? Can they be prevented by censorship or prior restraint?
Gab, the social media platform that was home to Robert Bowers, says “no” and is fighting back forcefully. Gab CEO Andrew Torba wrote on the site’s homepage:
In the midst of this Gab has been no-platformed by essential internet infrastructure providers at every level. We are the most censored, smeared, and no-platformed startup in history, which means we are a threat to the media and to the Silicon Valley Oligarchy.
Gab isn’t going anywhere.
It doesn’t matter what you write. It doesn’t matter what the sophist talking heads say on TV. It doesn’t matter what verified nobodies say on Twitter. We have plenty of options, resources, and support. We will exercise every possible avenue to keep Gab online and defend free speech and individual liberty for all people.
I suspect that Gab will have plenty of support, particularly now that the Pittsburgh tragedy has made it famous. The new rule of American democracy is that celebrity—good or bad—trumps all else. Gab can also count on the support of conservative right wing sites as well as liberal defenders of the First Amendment, like the American Civil Liberties Union.
Do we have the technology to find hate speech online?
The answer is “probably…but not totally reliably yet.” But we are getting there quickly.
The closest thing we have at the moment are companies like FAMA, an HR screening startup that uses AI to sift through posts of job applicants looking for things that are racist, sexist, violent, or otherwise objectionable. The company already has more than 100 customers with more than 1,000 employees each. I think it’s safe to predict that most major companies will be using a service like this in the near future.
Another company called Predictim is a service for people seeking caregivers, babysitters, or dog walkers. It goes even further than FAMA, asking candidates for permission to access their private posts and comments in addition to public ones. The resulting report assigns risk scores ranging from 1 to 5, overall and for categories that include drug use, bullying, and “bad attitude.” Because AI is easily biased by such information, both companies withhold gender and race information from the training data, so their AI systems evaluate only the contents of social media posts.
Privacy advocates worry that such systems can make basic errors that may ruin peoples’ lives. Said Jay Stanley, senior policy analyst at the American Civil Liberties Union:
The automated processing of human speech, including social media, is extremely unreliable even with the most advanced AI. Computers just don’t get context. I hate to think of people being unfairly rejected from jobs because some computer decides they have a ‘bad attitude,’ or some other red flag.
My take
Unlike the U.S. government which is required to provide basic uniform justice to all citizens, companies are not under any obligation to hire racists, misogynists, sex addicts, exhibitionists, or generally unpleasant people whose online postings suggest they might not be a “good fit.” If you’re looking for a job in the post-Facebook world, you should just assume that your online life will be examined and may be a factor in whether you’re hired or not. Companies aren’t allowed to discriminate on the basis of age, gender, race or religion but they do have the right to be discriminating.
I am a believer in First Amendment rights (with bans on child pornography and snuff videos and possibly, possibly bans on hate communities). The problem with cracking down on hate speech is that in the 21st century, each side of the left-right political divide believes the other side is doing it and their side is not.
Had you asked me in 2000 if the First Amendment was absolute and inviolate, I would have answered “absolutely.” Now, after 9/11, NSA’s illegal wiretapping, adtech, Facebook and Google and the rise of the Surveillance Nation, I’m not sure just how much more Americans are willing to give up in order to feel safe and part of an online community of peer. We’ve already lost the privacy war. Is freedom of expression next?
Make no mistake, this is all part of a wider public debate about ethics that has barely got started let alone attention. Right now, it is being left to corporations to decide. I’m with others who say this is a societal issue of much greater import. It requires a genuine collaboration between all actors – including the State and States. But in a world where the primacy of the commercial interests of those same corporations has led to a largely hands-off approach by government, I wonder whether it is possible to bring all stakeholders together.
Image credit - via Post-Traditional BuddhismRead more on: Future of workMachine intelligence and AIRegulation 