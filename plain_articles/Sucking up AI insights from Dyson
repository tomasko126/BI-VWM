
Members of the UK House of Lords Select Committee on AI are currently engaged in hearing evidence for a report on the “economic, ethical and social implications of advances in artificial intelligence”.
This is due to be published in March next year, but over the past few weeks the 13 members of the committee have heard from a variety of expert parties. While there has been, inevitably, a fair degree of repetition in some of the submissions, there have been some interesting voices aired, including Dr Mark Taylor, Global Strategy & Research Director, Dyson.
Dyson is best known as a UK success story in vacuum cleaner and air conditioning products, but also runs the Dyson Institute of Engineering and Technology, set up to “teach the next generation of engineering enthusiasts”. AI is of course set to play a huge role in the work of that next generation, but also has potential and practical applications right across Dyson’s business, according to Taylor:
In the product development process it is helping us to design better products—using high-speed computing and machine-learning techniques to optimise air paths in cyclones in vacuum cleaners, for example. It also enables us to make products that are much more personalised and differentiated, that are much more adaptive and which can adapt to their environment over time. That creates an opportunity to develop a new technology in a new area that brings a product benefit and allows us to be more successful as a company.
There are, on the other hand, wider potential issues that need to be addressed across society, around topics such as data privacy, algorithmic transparency and labour markets among others. Talyor made a strong point that while most talk about AI is built around future implications, the technology is already in place:
Most of us are interacting with AI on a daily basis, whether we are doing a search, using a voice assistant or online shopping. The list is endless. This year there has been a widely published study which suggested roughly two-thirds of consumers did not know they were interacting with an AI entity when in fact they were. That was a survey of about 1,500 people across half a dozen different countries. I do not know how well the survey was done but it seems plausible. That is the point: the algorithm—the AI—is intended to be invisible and behind the scenes.
To a very large extent, particularly as we are talking at the moment about narrow AI that is not a major issue. When an AI algorithm is making very significant life-or-death decisions, or near to, over an individual, transparency becomes essential. When it is translating some text for you from one language to another for your personal use on a website, maybe it is less important to know as a consumer how it is done. The context as to how AI is being used, for what purpose and how the individual is impacted by that is the most important lens to look through when thinking about how aware people should be.
Transparency
Questions of awareness and transparency are incredibly important, argued Taylor:
You have algorithms and data, and how data is used is incredibly important to individuals. I am sure we all care very deeply about our own data, as does everyone else in the rest of the country. Transparency around data use is important. The GDPR regulations that are coming in next year are very welcome and are a very good strengthening of data protection. There is room to go still further…and personal ownership of data may be something that we want to move towards as a society.
He added that for its part Dyson is very conscious of its responsibilties to its customers in this respect:
It is very important to be very clear with consumers how their data is going to be used. At Dyson we do not share data with any other company. We do not sell data. We have a very clear end-user licence agreement between individuals who use our products and services, and the company. We try to be very transparent about what that means and use very simple language. It is vitally important that there is transparency, honesty and ethical and moral principles behind how a company uses the data from consumers, and it should not do anything with it that it has not explained to the consumer it is doing.
With Dyson we try to explain how our products work. It is part of how we operate as a company. We try to explain the technology behind our products. With Artificial Intelligence and the use of machine learning, we would want to explain how we are using a technology to improve the product and be very transparent and open about that. We want to be very clear about how we are using the data and how we do not sell it or use it for any other purpose than to improve the performance of that product, and how we dissociate data from products for consumers and follow the law in doing that correctly.
With a possible eye back towards the Engineering and Technology Institute, Taylor flagged up an all-too-familiar issue – shortage of skills to meet the challenges and opportunities ahead:
It is extremely difficult to hire AI talent in the UK. It is a very important, growing and sought-after area, and graduates and postgraduates with machine-learning skills command many job offers and extremely high salaries. Yes, it is very difficult. The problem facing us starts at school. It starts with teaching computer science and STEM subjects, and encouraging their study, and bringing machine learning into the curriculum – as I note they are about to do in China – training our children and the future workforce in what will be one of the core skills, in order to be successful as individuals and as a society in the future.
It translates into university. We do not have enough STEM students at universities. We are not training enough people with these particular AI machine-learning skills. Therefore, we are not producing enough graduates or postgraduates in this. That is about looking at the curriculum and funding for schools and providing the right capability for schools to teach the curriculum and, obviously, expanding the number of places at university and postgraduate PhDs and MScs.
We also need to make sure that we can hang on to the graduates who are doing postgraduate training when they finish their master’s and PhDs. Some 70% of those in STEM are from overseas. We need to encourage them to remain in the UK and continue to pursue their discipline in industry or in academia, because we need to retain that talent that we have helped to train and develop here in the UK for the future. A broad response is required through secondary, through university and then at postgraduate level.
With company founder James Dyson a highly-vocal Brexit-er, building a strong tech workforce is clearly a priority for the company, but also for the UK itself. Taylor himself called for some strategic national thinking around this:
AI offers an enormous opportunity to the UK economy and the most important wish that I would have is for a comprehensive strategy around how the country is going to benefit from its exploitation. Maybe it is a bit of a cheap wish, but that spans education at secondary, university and postgraduate level and spans into industry and how industry can be involved in that strategy for funding, for retraining and for awareness for many segments. It would be a holistic strategy.
At the end of the day, Taylor describes himself as “incredibly optimistic about the future”, despite some of the challenges ahead:
The human race has been incredibly resilient and has had a great ability to deal with all those revolutions that have gone before and adapt and change and become stronger as a result. I do not claim to be able to see what will happen through this, but I remain very optimistic that we will find ways of adapting and using the technology for all our benefits.
My take
An interesting insight into some of the practical considerations from a UK manufacturing leader. Tomorrow, we’ll take a look at what Ocado had to say on the same subjects.
Image credit - Dyson Read more on: Future of workIoT robotics and AIMachine intelligence and AI 