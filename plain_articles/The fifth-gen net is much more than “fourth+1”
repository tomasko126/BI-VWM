
Peter Coffee
When we try to picture the progress of technology, it’s helpful to know about logarithmic scales. If we use a linear vertical scale, a graph of (for example) annual additions to global computer capacity looks as if we had only discovered computers in 2005; with a logarithmic scale, something like a Moore’s Law trajectory of improvement in microchip tech becomes a lot easier to visualize, albeit still difficult to grasp.
There’s a real risk, though, that a logarithmic measure of progress is almost too easy to apply. We may wind up congratulating ourselves on understanding what is actually just a gross measure of change, pleased by what we see on the speedometer – while failing to notice that there’s a whole new engine under the hood. That’s what’s happening right now with so-called “5G” networks. Long in the making, 5G is now down to small single digits of years to wait for broad deployment – but please, don’t just increment the “4G” on your smartphone screen. Don’t make the easy assumption that that this is merely the next step in network speed.
Yes, it’s easy to be distracted by 5G’s promised explosion of bandwidth, which makes even the extraordinary progress of the past ten years look like a slow warmup lap. When trying to set a baseline for comparison, it’s truly difficult to believe what a connection-poor world we’ve only recently left behind. I had to look this up before I believed it, but the first model of Apple’s iPhone—released eleven years ago—was only a GPRS– and EDGE-capable device. (Officially, EDGE means “Enhanced Data rates for GSM Evolution”, but what it means to me when I see it on a screen is that I’m beyond the edge of useful wireless connectivity.)
A year after the first iPhone came to market, in the same way that a first-gen Apple Watch is now retronym’d as a “Series Zero,” the 2007 iPhone came to be nicknamed the “iPhone 2G” when its 3G-capable successor was introduced. I dare you to claim that you remember being impressed, when 2008’s formally-named “iPhone 3G” promised a doubling of data rate compared to the debut device: rocketing up to a promised “typical download speed” of 1.4 Mbps. Yes, that was only ten years ago, and during the ensuing decade we’ve quickly grown accustomed to 4G LTE wireless bandwidths now on the order of 30 megabits per second (download).
Logarithmic
Let’s do some logarithmic ratios. Getting from 1.4 to 30 Mbps, over a period of ten years, pencils out to a doubling period of twenty-seven months: hardly a leisurely pace, though not startling compared to the Moore’s Law doubling period of just eighteen months. We risk a major error, though, if we continue with past practice in defining the next generation of wireless capability—the 5G network—in the familiar terms of just another exponential leap in data rates.
Yes, 5G will be fast – as exemplified by Qualcomm’s projected performance of 5 Gbps in a 5G modem, plausibly to be supported by many carriers’ networks by 2020. Getting from 30 Mbps in 2018 to 5 Gbps in 2020 would be a doubling period of only three and a quarter months, which leaves even Moore gasping for breath – but thinking of 5G as 4G done faster is like thinking of a computer as merely an electronic abacus. It’s not completely wrong, but it’s only a small fraction of what’s right.
In what’s probably the shortest possible description of the real change, one 2015 article was headlined “5G is coming! Wireless telecom is dead, long live wireless IT”. 5G is one of those changes that require us to turn our understanding inside out: we have to move beyond thinking of networks as mere conduits of connection linking nodes of computation. We’ll do better to think of 5G as a global computing fabric, with some edge devices that let it mimic a telephone system – along with doing many, many more interesting things.
I experienced, earlier this month, a deep dive into a near-term 5G future at the iconic Bell Labs, birthplace of the transistor – along with other incidental achievements, including the accidental discovery of the Big Bang. Hosted by Nokia, that “Converge” event included a full day of seriously technical presentations; it concluded with a preview tour of a Disneyland-class immersive demonstration of a connected factory, run by a fully software-defined collection of network capabilities. This has been sketched out by concepts and prototypes for many years, but what I saw at Bell Labs was real hardware and highly configurable software – taking huge steps beyond today’s crude dichotomies of cloud versus on-premise options.
Marcus Weldon, president of Bell Labs and Corporate CTO of Nokia, had crisply defined the challenge in his remarks at Converge earlier that day: to break today’s stagnation of productivity, he asserted, we need an Internet that is a “six 9s, low latency” foundation. During the demonstration later that evening, I had an opportunity to work with a robot that was being controlled by a network with typical-for-today levels of network latency and packet loss: it was a clumsy (and in real life, probably dangerous) co-worker. Using the software-defined management environment to adjust network parameters, and optimize for the shop-floor WiFi coverage map, we were able to achieve a huge improvement in accuracy and responsiveness. Seeing is believing, but not being whacked by an overshooting manipulator arm is being truly convinced.
The “cloud computing” that we have today is a cloud of computation, relationship and transaction; the cloud that’s required is one of measurement, notification and action. Fast local resources will have to collaborate with channels and nodes of aggregation for analytics and machine learning. We’ll be optimizing performance versus cost, and orchestrating shared resources at massive scale.
This is not about delivering cat videos faster, or browsing the new fall clothing line more easily. The Internet of today, said Weldon, is “a blip: it’s funded by advertising, which drives shopping, which is the fastest-growing use case.” The fifth generation turns the Internet inside out, transforming it from plumbing that connects computers into a massively distributed computer that delivers a dynamically adjustable imitation of plumbing. Changing our thinking will be much harder than speeding up the things we do today.
 
Image credit - Pinterest/SalesforceRead more on: CRM and customer experienceDigital enterprise in the real worldInfrastructureInternet of ThingsIoT robotics and AIMachine intelligence and AIPartner ZoneProductivitySalesforceUser experience 