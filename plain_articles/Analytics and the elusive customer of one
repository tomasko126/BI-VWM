
Trainline travel details via email
The current state of analytics is making it difficult to understand what is strategic and what is tactical. Right now, I see numerous experiments with different approaches and softwares leading to a dizzying array of outcomes. To date, I’ve not seen a ‘joined up’ approach that I could take to a CEO and credibly call a ‘strategy’ that will make an appreciable difference to the bottom line. Why? Phil Wainewright’s discussion of the Trainline’s approach to data and data analysis provides useful clues.
Holes in the story
One the one hand the Trainline story speaks to the imagination of those working towards Wainewright’s Valhalla of a frictionless enterprise. On the other hand it speaks equally to the less than joined up nature of supply chains. Slap bang in the middle are the analytics providing the food for decision making thought. Apart from the mandatory value add statements in the Trainline story, check these two snippets:
There’s also potential to mine Trainline’s historic data to give customers useful information, for example to let them know which are the busiest trains and which are likely to have more space available. Holt can also envisage using the data to offer more airline-style price management, but as Trainline doesn’t set prices itself — that’s up to the train operators — for now it has to content itself with other aspects of the customer experience.
There’s your imagination piece of the puzzle right there.
But beyond its own use of data, much of what Trainline can achieve depends on interactions with the train operators and how much investment they are willing to put into enabling those more magical journeys. E-ticketing is one example. At the moment it’s available on 30% of routes, says Holt. But for a seamless experience, it requires ticket barriers at the station that can read a QR code from a mobile phone. No operator is currently completely e-ticket enabled, and some have barely started, although the government is encouraging more aggressive adoption of the technology.
I knew Phil was writing this piece and in email pointed out to him that QR reader facilities don’t exist at Kings Cross, Bradford, Manchester or Harrogate – stations I’ve used the last few weeks, twee of which are major UK rail hubs. The ticket barriers have to be manually opened by staff wasting time inspecting the e-ticket. I could also add that the QR based e-ticket is not consistently offered on the mobile app. On the plus side, the tickets can become part of an expense report. So yes, hats off to Trainline for imagination and a thoughtful approach to the value analytics can bring. But in the real world, much more needs to be done. And it is this ‘what’s next?’ question that vexes me.
Bullshit and the spreadsheet
This was brought into sharp focus for me during a conversation with Nick Hortovanyi. You won’t find him pontificating on the inter webs or flogging the next shiny new thing. He’s a a smart coder who has worked on some honking big projects involving capital intensive industries where sensor technology has not only been around since forever but is rapidly expanding i its usage and deployment. He said something that stopped me in my tracks:
I’m sick and tired of listening to the analytics bullshit around Internet of Things. The great steps forward happen when you see a fundamental change in the approach to analytics where the customer is at the center. Where is that next step?
That made me sit up because thinking back, the last huge stride forward in delivering compute value came with the familiar spreadsheet. That was sometime around 1979. To this day, the spreadsheet remains the most ubiquitous tool for creating forms of analysis, whether it be consolidated account reporting or what-if? analysis of increasing complexity. As one colleague said:
You’ll have to rip the spreadsheet from my cold dead hands before I’ll abandon it for something else.
Plenty of people agree the spreadsheet remains useful but that the dangers of its use in unsuspecting hands are at times overwhelming. It’s a topic I’ve regularly opined on since 1996. But it is that ‘something else’ that’s elusive.
The last few years, many colleagues have been drawn to the promise of visualization technology of the kind Tableau and Qlik have successfully championed, usurping the likes of BOBJ and Hyperion along the way. But as we’ve seen in recent reporting quarters, the gloss has gone off those solutions as companies like Microsoft have come in with cheaper and, arguably easier to use solutions that ultimately dovetail to their core products – like the ubiquitous Excel spreadsheet. Even then, you can easily argue that ‘viz’ is only an end user enabling technology that makes data easier to consume and understand. It’s not a fundamental shift.
Thinking further afield, Good Data recently approached me wanting to brief on analytics that serve to drive the business. As I considered what they are saying, it struck me that they were describing something that’s far from new.
The ‘customer of one’
At diginomica, we’ve used web analytics from day one as a way of discovering what drives content, which lies at the heart of how we’ve built the business model. It’s an evolving requirement and one to which we devote considerable thinking time. I’m not convinced we’ve cracked it – yet – but at its essence is the idea that if we are to succeed in what we do then we must serve the ‘customer of one.’
As I thought more about this problem, it occurred to me that business is not really solving for the ‘customer of one’ but mostly generalizing for revenue in a transactional manner. The customer is not the center of the arrangement but the target.
It concerns me that what we’re seeing are siloed applications. Build me a revenue discoverer here, find me an optimal cost path there and so on. All of which is fine as tactical statements but doesn’t tell me how the bottom line is impacted overall. In the Trainline case, the company won’t see optimal results until the physical infrastructure is in place with which to offer the efficiencies the Trainline envisages:

We know that customers spend up to 20 minutes queueing at ticket machines. The amount of time people are wasting queuing for pieces of dead tree when they could just go [on their phones], ‘I’ve bought it, I’m going to go.’
Buying it on the way to the station would be much better. We’ve been working with the industry to roll it out and we’ll be doing a lot more of that this year.

Getting from here to there in this case requires much more than great analytics. It requires a vision that can be both communicated and acted upon across an entire industry. Pulling that off will be no mean feat.
But even that is only one half of the equation. The Trainline is looking for revenue optimization through a better customer buying experience, because that’s what its business model depends upon. It begs the question about how service delivery is improved, once the sale is made and how that will impact the Trainline’s long term prospects. That got me revisiting the KPMG report, Now or Never: 2016 Global CEO Outlook (PDF.)
Are CEO’s viewing the world correctly?
Barb Zinck’s opus, Why do marketers struggle to do analytics well? references the KPMG report noting that:
84% of CEO’s indicated their concern about the quality of the data they use to make decisions.
I was much more concerned about the plethora of other findings summarized in this image:
KMPG – key findings, 2016 CEO Outlook
They’re not easy to read on this graphic (click to pop out) but I was astonished at the high level of concern about putting customers central to their strategies at 88% but the complete absence of collaboration as a topic to consider as part of that customer relationship. Instead, the emphasis is on partner collaboration. Analytics is core to those relationships and yet again, it isn’t a stand out in this report.
In that context, the cynic in me is hardly surprised by Zinck’s question or her ongoing concern.
As I pick over the various tales and case stories, hear pitches telling me how fresh approaches to analytics are discovering revenue drivers, hear about the latest thing that IBM Watson has done and so on, I can’t help but wonder why we are not hearing about a more expansive vision.
Instead of hearing about things that genuinely puts the whole customer experience first, with analytics that flow the entire length and breadth of that experience, I am much more likely to hear about point solutions, pain point solutions or simply fluff. My sense is that technology providers who’ve got their hands on a shiny new toy look out at the sea of data in front of them and calculate that only a quick win matters.
The collaboration nexus
There is an approach, hidden away in Rachel Happe’s Facebook time line, where she says:
Traditional leadership is focuses on the transaction (sale, pitch, stock price, vote). Collaborative leadership focuses on the relationship.
People with traditional leadership mindsets are confused by collaborative leadership – because they want the pitch, not the question.

But the pitch is a transaction – it can be accepted or rejected. Questions draw you in and force you to declare yourself. They force you to get involved and be part of the solution.
If you are focused on the transaction, each transaction will cost you something. If you are focused on the relationship, the transactions will come organically and in the end be cheaper.
To me, this is networked/community leadership. Easy to dismiss in the short-term, incredibly resilient and powerful in the long-term.

Wow! Is that a powerful set of statements or what? Happe’s statement is made in a political context yet is equally applicable to the business. So where do analytics fit into THIS equation?
Analytics at petabyte scale
I’m of the view that in order to understand individual customer need, business needs a LOT of data, much of which should be about understanding customer behavior resulting from the customer experience. Call it social or big data if that makes you feel more comfortable. I prefer a degree of precision in what I am trying to find.
Simply trying, for example, to stem the tide of cart abandonment with annoying emails ain’t going to cut it. None of this is easy from a technical standpoint.
Which data do you examine? How do you figure out which statistical techniques are going to be appropriate? How do you go from apparent cause and effect to a deep understanding of behaviors? What can we learn from those behaviors? Where does creative thinking slot into the process of designing new experiences? Where the heck are the tools that are going to give operational front line decision makers a clear path to action?
Hortovanyi says that today’s installed sensor technology is only tackling a fraction of what is possible track side. I countered with tales about the gigabytes of data Formula 1 race cars generate and wondered if similar approaches could not be applied to more sedate forms of transportation. The moment you do that, you set up a requirement for massive compute needs, a la Spark and other emerging, yet still complex technologies.
Regardless, and as the Trainline example informs us, there are plenty of ways in which to infer behaviors up to the point of buying. It’s what happens after that which I care about.
It seems for example that many of the transportation companies have singularly failed to understand how to manage poor customer experiences. Just how many Tweets or Facebook mentions does it take before a train operator/airline/name your favorite here takes notice or spots a trend? Maybe this from Emily Coltman gives a special clue:

Not my experience on Grand Central to London this week but heh ho.
Data at rest, data in flight
That brings me to the financial numbers which, at the end of the day, form the basis (but are not the only measure) for analyzing and understand shareholder value. Those are always historical, they’re never real-time. Not even remotely close. They’re at best a guesstimated snapshot based upon modified data at rest. But then some of that snapshot data such as accounts receivable can be extremely useful when thinking about field service requests and renewals.
Why wouldn’t you get the field service agent to pick up a check on an old outstanding account while visiting the customer? But then what if the customer has paid earlier in the day? Do we have systems capable of instantly recording that? No. Our global banking systems are so fragmented and reliant on latency as a way to earn revenue, that it is nigh on impossible to show cleared items in less than a day.
Even when set against these limitations, I see precious few examples where data at rest and in flight are merged in such a way as to help people take operational decisions. Even then, I have yet to see any examples that demonstrate how different strategies are A/B tested so as to improve overall outcomes.
Finally
It is clear to me that we are the darkness before the dawn of a new age in analytics. Colleagues and vendors will bang on about the latest shiny new thing in ‘big data’ or the even more nebulous ‘internet of things.’ If C-level decision makers are confused then none of us should be surprised. But a continuing of silo-based, departmental, point problem thinking is not going to solve the genuine problems that many businesses face today.
We desperately need a visionary approach where the customer is central to the discourse around products and services and where the transaction is a natural rather than forced outcome. We need forms of analytics that talk directly to the question of behaviors, but not in a creepy, we’re-looking-over-your-shoulder kind of way. We need analytics that operational managers can easily understand and which allow for sharing with any interested party. We need analytics that help us better see how to solve the whole customer experience while driving forward with the notion of the frictionless enterprise.
In short – we need something fundamentally new. Right now, I’m not seeing it.
 
Image credit - images clipped from named sources, featured story image via © Rawpixel.com - Fotolia.comRead more on: Analytics planning and data analysis 