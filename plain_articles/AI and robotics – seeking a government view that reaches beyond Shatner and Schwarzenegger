
There’s been much private sector discussion of the potential for AI, machine-learning and robotics in recent months, with a flurry of vendors pushing these from a technology revolution point-of-view in the past few weeks alone. 
But how ready is government for such a revolution, particularly when it comes to the social and ethical implications? Not very, is the grim conclusion of an inquiry report from legislators in the UK government, which calls for the creation of a Commission on Artificial Intelligence to be established at the Alan Turing Institute, with a brief to examine the social, ethical and legal implications of recent and potential developments in AI.
The inquiry, by the Science and Technology Select Committee of the House of Commons, did of course have a UK-centric brief, but the questions being asked and the recommendations that result have a wider remit than just Great Britain. The specific terms of the inquiry were to address: 

The implications of robotics and artificial intelligence on the future workforce and job market, and government’s preparation for the shift in the skills base and training that this may require.
The extent to which social and economic opportunities provided by emerging autonomous systems and artificial intelligence technologies are being exploited to deliver benefits to the nation.
The extent to which the funding, research and innovation landscape facilitates the UK maintaining a position at the forefront of these technologies, and what measures the Government should take to assist further in these areas.
The social, legal and ethical issues raised by developments in robotics and artificial intelligence technologies, and how they should be addressed.


My expectations weren’t high going into this report. Back in 2013, the UK Government did identify AI and robotics as one of its so-called Eight Great Technologies in which it aspired for the UK to take a lead. That aspiration has not been backed up by suitable investment, of course.
As for the Commission proposal for the Alan Turing Institute, it’s to be hoped that won’t follow the route of the Robotics and Autonomous Systems (RAS) Leadership Council, announced in 2015 and of which there is currently no sign.
And when a report into technology innovation trots out the ‘science fiction becoming science fact’ cliche, it doesn’t bode particularly well for the originality of the thinking to be found within. So it was with some foreboding that I read: 

Artificial intelligence has some way to go before we see systems and robots as portrayed in the creative arts such as Star Wars. At present, ‘AI machines’ have narrow and specific roles, such as in voice-recognition or playing the board game ‘Go’. But science fiction is slowly becoming science fact, and robotics and AI look destined to play an increasing role in our lives over the coming decades.

But in fact, the report does go on to isolate some interesting talking points for consideration, such as: 

How to take steps to minimise bias being accidentally built into AI systems.
How to ensure that the decisions AI systems make are transparent.
How to instigate methods that can verify that AI technology is operating as intended and that unwanted, or unpredictable, behaviours are not produced.

Skills and education
The skills – or lack of skills – issue was inevitably one that came to the fore during the evidence-gathering stage of the inquiry, with Professor Rose Luckin, Chair of Learning with Digital Technologies, UCL Institute of Education, University College London, observing:


I do not feel that at the moment we are equipping either students in school or workers in the workforce with the requisite skills to know how to adapt themselves to use the automation they are being offered to best effect. We need to take that on board and make some changes to address it.

Luckin argued that the current focus of the education system is askew: 

Of course, students need to understand the basic subjects, but the very things on which we focus our education system are the routine cognitive skills that are the easiest to automate. We need to make sure that students also gain what are called 21st- century skills. They change, and they will change, because as the workforce changes, the skills we need will change, but they are negotiation, communication and being able to synthesise multiple sources of information. It is probably also artificial intelligence and knowing how to make the most of the kinds of automated systems that will be in the workplace when you get there.
Delivering some of the routine cognitive subject matter can be done very effectively and efficiently by artificial intelligence technologies. What we cannot do is deliver exactly the 21st-century skills that we need learners to have: socio-emotional intelligence, negotiation and so on. Who is going to train the teaching workforce so that they know how to take best advantage of the sort of AI technologies that can be for them the saviour of the situation, in terms of helping them make sure the future workforce is skilled to the appropriate level?

Dave Coplin, Chief Envisioning Officer at Microsoft, while recognising the importance of STEM skills, wanted to see the importance of non-tech skills recognised:


Without art and creativity, innovation is dead. We could have a bunch of scientists, which would be brilliant, but their ability to be creative in the future world of work is the thing that makes them successful…We do not need to frighten them off with a bunch of science; we need to show them how creative they can be and how it is a blended world.

He added: 

My point is not that you need more people with ponytails and beards, but that you need to inspire lots of people to think very differently. For me, it is about creativity. We should not be having a conversation with kids about robotics and AI, but about what they can make with it, what they could do with it. When you do that and you see their lights go on, they do not care whether they are using robots or AI; they want to engage with it. If we can do that, we create a positive influence and a positive aspiration about how we can lift humanity further.

The AI workforce 
As to the impact on the workforce,  Professor Nick Jennings of the Royal Society Working Group on Machine Learning, made the point that AI and robotics can be an augmenter, not a destroyer of professional white collar activities:


 I think they will generate a whole load of new jobs around them in the way data science and data scientists created them. It has gone away from augmenting basic operations on data to letting people concentrate on higher-level things, and then a whole load of data scientists are concerned with curating and presenting that data and doing the analytical tools for it. 
Continual retraining is going to happen ever more. The view that you train at university when you are 18, have one career and that is it will disappear over time. It is important that universities and individuals are willing, and we have structures that let people retrain continually.

Angus Knowles-Cutler, Vice Chairman and London Office Senior Partner, Deloitte, was keen that the debate was not reduced to a binary position of human v robot, but should be thought of in terms of tasks within jobs: 

One of the reasons I became interested in this a couple of years ago was that I mapped out my working day when I first started as a graduate analyst in 1985. In my 12-hour day I went to a physical library and looked at things called microfiches. Some people may know what a microfiche is, but it is a very generational divide. Six librarians would help me. We did not have a computer, so I worked out everything on a hand calculator ledger. That was a 12-hour day. 
Last year I got one of my graduate colleagues to do the same 12-hour day. I was never the swiftest, but she did it in 40 minutes. The very mundane, repetitive tasks had gone out of my day, but the reality is that it did not destroy my industry, and in fact my industry is much larger than it was back in 1985, so there is a subtlety there that is very important. These are tasks where technology is enabling us to be more effective as productive workers.

Where those productivity improvements are to be found varies across industries, he added, and will be visible over differing periods of time: 

In sectors where we have seen a lot of jobs go in the last 15 years—300,000 in retail and 100,000 in manufacturing—the flipside is that those are the sectors where we have seen productivity improvements. The UK car industry is a very successful one. We are one of the leading countries in the world, but with many fewer people working in car manufacturing than there were in the 1970s. Some sectors, such as manufacturing and retail, have adopted technology and therefore become more productive. Other sectors, particularly some of the service areas—business services, professional services and financial services—have been fairly anaemic in their productivity gains since the financial crisis, but there is technology there that is yet to be implemented.

My take 
The number of ‘clever’ references from legislators on the inquiry committee to popular sci-fi movies was frankly depressing – Terminator, Star Trek (The Wrath of Khan in particular for some unknown reason!), Demolition Man, out they all came. If the level of genuine understanding of the issues involved here are starting from a base level of Stallone, Schwarzenegger and Shatner, there’s a long way to go here. 
That said, a journey of a thousand miles begins with a single step etc etc. As to specific recommendations, the inquiry makes several key points: 

Digital exclusion has no place in 21st century Britain…the Government must commit to addressing the digital skills crisis through a Digital Strategy, published without delay.
A standing Commission on Artificial Intelligence [should] be established, based at the Alan Turing Institute, to examine the social, ethical and legal implications of recent and potential developments in AI. It should focus on establishing principles to govern the development and application of AI techniques, as well as advising the Government of any regulation required on limits to its progression. It will need to be closely coordinated with the work of the Council of Data Ethics which the Government is currently setting up. Membership of the Commission should be broad and include those with expertise in law, social science and philosophy, as well as computer scientists, natural scientists, mathematicians and engineers. Members drawn from industry, NGOs and the public, should also be included and a programme of wide ranging public dialogue instituted
The Government should, without further delay, establish a RAS Leadership Council, with membership drawn from across academia, industry and, crucially, the Government. The Leadership Council should work with the Government and the Research Councils to produce a Government-backed ‘National RAS Strategy’; one that clearly sets out the Government’s ambitions, and financial support, for this ‘great technology’. Founding a ‘National RAS Institute’, or Catapult, should be part of the strategy. 

It’s hard to disagree with any of that from a to-do list point of view, so long as it actually happens. It’s going to take more than Watson or Einstein to predict that outcome. 
Image credit - Replacement Of Humans By Machines © ktsdesign - Fotolia.comRead more on: Governing identity privacy and securityHCM and the digital future of workIoT robotics and AI 