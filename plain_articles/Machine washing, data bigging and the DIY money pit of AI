
Artificial intelligence was one of the dominant themes at this year’s HR Tech World conference in Amsterdam last week, both on the keynote stage and on the show floor. But we’re early in the hype cycle for AI technology. That means vendors are over-promising what can be achieved with it and there are few proven enterprise use cases — but many ways to squander money without any useful payback.
In a conference that always puts the future of work center stage, there was also much angst about the impact of robots on the workforce. Will they put us all out of work? Or will it be a case of augmenting our abilities so that we can achieve more in our jobs? In an erudite review of the current frontiers of AI innovation, Nick Bostrom, the Oxford academic who as Founding Director of the Future of Humanity Institute has written about the existential threat posed by superintelligence, suggested we should not worry just yet, pointing out the limitations of current AI technology:
What is intuitively easy for a human might not be so easy for these neural networks.
For many HR professionals, the existential threat they face is far closer to home. Even without the aid of AI, much of the routine administrative work traditionally performed by HR teams is being eliminated by the roll-out of self-service automation along with standardized processes and datasets. At the same time, all this digital transformation is augmenting their ability to take up more value-added advisory and analytics roles. To that extent, the robots are already taking over HR, replacing some jobs but enabling others. It is a disruptive shift that requires retraining and careful change management for those displaced.
Adding AI merely amplifies this existing trend, and as with all new technologies, the change seems gradual at the time. It’s only when we look back at the end of the next decade that we’ll realize how far we’ve come.
For now, the hype far exceeds the reality and this year’s HR Tech World (now rebranding as Unleash) was notable for three phenomena that show just how early we are in the AI wave. I’m calling them machine washing, data bigging and the DIY money pit of AI.
Machine washing of existing products
Every software vendor wants to have an AI story — as Oracle CEO Mark Hurd joked at his company’s OpenWorld conference earlier this month, “Say AI in front of my company logo, my stock goes up.”
We’ve seen the same phenomenon with every other new trend that takes hold in the tech industry, whether it’s big data, IoT or cloud computing. This even gave rise to the term ‘cloud washing’ to describe a vendor that took an existing product and hosted it in the cloud just so they could claim to have a cloud story — but without actually having to invest in building a cloud-native product.
So let’s use ‘machine washing’ to call out the AI equivalent. This is when a vendor adds a veneer of either AI or machine learning to an existing product without actually making it any smarter. The classic example is to write an Alexa skill or a Google action so people can speak commands to an application instead of typing them in. That doesn’t make the app any more intelligent — using a third-party voice assistant doesn’t add any AI to the underlying application.
A more subtle form of machine washing is when a vendor has an existing big data analytics engine and starts describing it as artificial intelligence or cognitive computing. This is simply substituting one buzzword for another. Indeed, some big data analytics engines are so long in the tooth that they date back to the time when expert systems were the thing. They’ve survived to see the AI hype go full circle and come back again.
But none of these utilize the latest generations of machine learning, and particularly deep learning, that have emerged in recent years. These neural networks can be trained to recognize patterns, and sometimes even train themselves. They can then apply these pattern recognition skills to new data in order to find hitherto undetected patterns. This is the breakthrough that takes traditional data analytics beyond the purely descriptive and diagnostic (what happened and why) into the realms of predictive and finally prescriptive (what’s likely to happen and what to do about it).
There were vendors showing off examples of prescriptive analytics powered by machine learning at last week’s event. One of the most interesting examples to my mind was Infor’s use of AI to recommend the best people to join a team. This analyzes the characteristics of existing team members and potential additions, and suggests who might be the best fit to round out the team. It’s a new variation on the more common example of AI suggesting the most suitable new hires or advising on succession planning. Come to think of it, there are precious few AI applications in the HR field outside of candidate fit in some form or another. Which is why most vendors resort to machine-washing existing apps for lack of anything better to offer.
Data bigging – who has the most?
The main reasons why candidate fit is such a commonplace example is that this is where the most data exists. One of the primary determinants of a successful outcome from deep learning is the volume of data available. The more data you can feed into the model, the more accurately it can learn to detect and recognize patterns.
This gives rise to the second phenomenon that was evident at last week’s event, of vendors ‘bigging up’ the volume of data they have available to feed into their machine learning models. Infor’s secret sauce is a standardized assessment that it claims has already been taken by 20% of the US workforce. Cornerstone points to its historical data from 32 million users of learning, performance management and other applications. NGA HR talks up the 65 million cases its helpdesk has handled since 2004. It’s the same story from every vendor, seizing on the most impressive number it can find to convey the breadth and depth of its data store.
One important factor here is whether the vendor has permission from its customers to use their data in this way for machine learning or benchmarking purposes. Some were far-sighted enough to get this consent many years ago. Others have only recently thought to do so.
But quoting these numbers begs the question of how relevant this data is. If it’s not from the same industry, or the same demographic, or not recent enough to have the right job roles and skills, then it may not be predictive for a specific customer’s use case.
Many of the real-world use cases for AI in recruitment appear to be from the retail industry, where the volume of staff, the high turnover and the narrowness of the skill base all contribute to the accuracy of the predictions. But just because a model can show positive results when recruiting an assistant for a shoe store, it doesn’t necessarily follow that the same model will help you, for example, find the best nuclear physicist to join your fusion research team. Buyers must carefully examine the vendor’s data credentials and whether they’re relevant.
The DIY money pit of AI
The third phenomenon was less visible at last week’s show, but one talking point hinted at its existence. In a New York Times article published the weekend prior, Cade Metz revealed the current scale of the AI talent war:
Typical AI specialists, including both PhDs fresh out of school and people with less education and just a few years of experience, can be paid from $300,000 to $500,000 a year or more in salary and company stock, according to nine people who work for major tech companies or have entertained job offers from them.
Whenever a new technology trend takes hold, people tend to compete to build their own unique version. The most extreme example has been cloud computing, where for many years enterprises persisted in trying to build their own private cloud before finally realizing that public cloud providers can do the job much more cheaply and effectively.
Like cloud computing, AI is an activity where economies of scale are paramount. With the likes of Amazon, Google, Microsoft and a handful of other high-volume, global players investing in building machine learning engines at scale, anyone else who is trying to compete to do the same is really just throwing their money away. Instead of attempting to build do-it-yourself machine learning capabilities, it makes much more sense to become expert instead at using the AI engines and tools the leading players are making available to use on-demand.
Enterprises therefore should not be looking to build their own AI data centers, but instead should be investigating how to use the AI tools available from Amazon, Microsoft and Google. Similarly, HR vendors that are using these platforms are more likely to stay up-to-date with the latest AI techniques than if they build their own proprietary AI engines. They should concentrate their resources instead on understanding how to apply data science to their specific operational and industry domains, so that they can work out how to provide relevant outcomes for their customers.

Image credit - Row of washing machines in laundromat © PiXXart Photography - Fotolia.comDisclosure - Infor and Oracle are diginomica premier partners at time of writing. Read more on: HCM and the digital future of workMachine intelligence and AI 